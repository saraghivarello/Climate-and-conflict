{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# Merge df_with_dummies with displacement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:36:53.158014Z",
     "start_time": "2021-01-04T16:36:50.182287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/.local/lib/python3.8/site-packages/libpysal/cg/alpha_shapes.py:39: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def nb_dist(x, y):\n",
      "/home/sara/.local/lib/python3.8/site-packages/libpysal/cg/alpha_shapes.py:165: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def get_faces(triangle):\n",
      "/home/sara/.local/lib/python3.8/site-packages/libpysal/cg/alpha_shapes.py:199: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def build_faces(faces, triangles_is, num_triangles, num_faces_single):\n",
      "/home/sara/.local/lib/python3.8/site-packages/libpysal/cg/alpha_shapes.py:261: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def nb_mask_faces(mask, faces):\n",
      "/home/sara/.local/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import libpysal.weights as lpw\n",
    "import spreg\n",
    "import pandas as pd\n",
    "import pysal as ps\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:36:53.489678Z",
     "start_time": "2021-01-04T16:36:53.160457Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_dummies= pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\df_with_dummies.csv\")\n",
    "#states_gdf = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "\n",
    "df_dummies= pd.read_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/csv/df_lags_2016_n4.csv\")\n",
    "states_gdf = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/som_adm_ocha_itos_20230308_shp/som_admbnda_adm1_ocha_20230308.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\displacements\\UNHCR-PRMN-Displacement-Dataset - Somalia.xlsx\")\n",
    "df = pd.read_excel(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/displacements/UNHCR-PRMN-Displacement-Dataset - Somalia.xlsx\")\n",
    "df = df[(df['Reason']=='Drought related')]\n",
    "df['Current (Arrival) Region'] = df['Current (Arrival) Region'].str.replace(' ', '_')\n",
    "df['Previous (Departure) Region'] = df['Previous (Departure) Region'].str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= df[\"Month End\"]\n",
    "v=v.values\n",
    "dt = [datetime.strptime(v[i], \"%d/%m/%Y\") for i in range(len(v))]\n",
    "q=[]\n",
    "\n",
    "for i in range(len(dt)):\n",
    "    q.append(datetime.timestamp(dt[i]))\n",
    "    \n",
    "df.insert(loc=3, column='date_timestamp', value=q)\n",
    "df = df.sort_values(\"date_timestamp\")\n",
    "\n",
    "df['Month End'] = pd.to_datetime(df['Month End'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = df.groupby([pd.Grouper(key='Month End', freq='M'),'Previous (Departure) Region', 'Current (Arrival) Region'])['Number of Individuals'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = aggregated_data.index.get_level_values('Month End').unique()\n",
    "districts = aggregated_data.index.get_level_values('Previous (Departure) Region').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts,districts], names=['time', 'Previous (Departure) Region','Current (Arrival) Region'])\n",
    "\n",
    "disp_data = aggregated_data.reindex(all_combinations, fill_value=0).reset_index()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_matxs = disp_data.pivot_table(index=['time','Current (Arrival) Region'], columns='Previous (Departure) Region', values='Number of Individuals', aggfunc='sum').reset_index()\n",
    "disp_matxs = disp_matxs.rename(columns={'Current (Arrival) Region': 'admin1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the day from the date\n",
    "disp_matxs['yr_mth'] = disp_matxs['time'].map(lambda x: x.strftime('%Y-%m'))\n",
    "disp_matxs = disp_matxs.drop(columns=['time'])\n",
    "df_dummies['yr_mth'] = pd.to_datetime(df_dummies['time'], dayfirst=True).map(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "df_merged = pd.merge(df_dummies, disp_matxs, on=['yr_mth', 'admin1'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column with the sum of the displacements\n",
    "df_merged['sum_disp'] = df_merged.iloc[:, -18:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/csv/df_lags_2016_n4_disp_d.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for normalized data\n",
    "normalized_df = pd.DataFrame(columns=disp_matxs.columns)\n",
    "\n",
    "# Iterate through unique yr_mth values\n",
    "for yr_mth in disp_matxs['yr_mth'].unique():\n",
    "    # Select rows for the current yr_mth\n",
    "    subset = disp_matxs[disp_matxs['yr_mth'] == yr_mth].copy()\n",
    "    \n",
    "    # Extract the matrix values and convert to a NumPy array\n",
    "    matrix_values = subset.iloc[:, 1:-1].values\n",
    "    \n",
    "    # Perform normalization (e.g., min-max scaling)\n",
    "    min_val = np.min(matrix_values)\n",
    "    max_val = np.max(matrix_values)\n",
    "    normalized_matrix = (matrix_values - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Replace the original matrix with the normalized matrix\n",
    "    subset.iloc[:, 1:-1] = normalized_matrix\n",
    "    \n",
    "    # Append the modified subset to the new dataframe\n",
    "    normalized_df = pd.concat([normalized_df, subset])\n",
    "\n",
    "# Reset the index of the new dataframe\n",
    "normalized_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_aw=normalized_df[normalized_df['yr_mth']=='2016-01']\n",
    "w_aw = w_aw.drop(columns=['yr_mth', 'admin1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
