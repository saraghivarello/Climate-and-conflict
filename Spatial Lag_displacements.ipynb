{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# Merge df_with_dummies with displacement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:36:53.158014Z",
     "start_time": "2021-01-04T16:36:50.182287Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import libpysal.weights as lpw\n",
    "import spreg\n",
    "import pandas as pd\n",
    "import pysal as ps\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:36:53.489678Z",
     "start_time": "2021-01-04T16:36:53.160457Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_dummies= pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\df_with_dummies.csv\")\n",
    "#states_gdf = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "\n",
    "df_dummies= pd.read_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/csv/df_lags_2016_n4.csv\")\n",
    "states_gdf = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/som_adm_ocha_itos_20230308_shp/som_admbnda_adm1_ocha_20230308.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\displacements\\UNHCR-PRMN-Displacement-Dataset - Somalia.xlsx\")\n",
    "df = pd.read_excel(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/displacements/UNHCR-PRMN-Displacement-Dataset - Somalia.xlsx\")\n",
    "df = df[(df['Reason']=='Drought related') | (df['Reason']=='Flood')]\n",
    "df['Current (Arrival) Region'] = df['Current (Arrival) Region'].str.replace(' ', '_')\n",
    "df['Previous (Departure) Region'] = df['Previous (Departure) Region'].str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= df[\"Month End\"]\n",
    "v=v.values\n",
    "dt = [datetime.strptime(v[i], \"%d/%m/%Y\") for i in range(len(v))]\n",
    "q=[]\n",
    "\n",
    "for i in range(len(dt)):\n",
    "    q.append(datetime.timestamp(dt[i]))\n",
    "    \n",
    "df.insert(loc=3, column='date_timestamp', value=q)\n",
    "df = df.sort_values(\"date_timestamp\")\n",
    "\n",
    "df['Month End'] = pd.to_datetime(df['Month End'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = df.groupby([pd.Grouper(key='Month End', freq='M'),'Previous (Departure) Region', 'Current (Arrival) Region'])['Number of Individuals'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = aggregated_data.index.get_level_values('Month End').unique()\n",
    "districts = aggregated_data.index.get_level_values('Previous (Departure) Region').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts,districts], names=['time', 'Previous (Departure) Region','Current (Arrival) Region'])\n",
    "\n",
    "disp_data = aggregated_data.reindex(all_combinations, fill_value=0).reset_index()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_matxs = disp_data.pivot_table(index=['time','Current (Arrival) Region'], columns='Previous (Departure) Region', values='Number of Individuals', aggfunc='sum').reset_index()\n",
    "disp_matxs = disp_matxs.rename(columns={'Current (Arrival) Region': 'admin1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the day from the date\n",
    "disp_matxs['yr_mth'] = disp_matxs['time'].map(lambda x: x.strftime('%Y-%m'))\n",
    "disp_matxs = disp_matxs.drop(columns=['time'])\n",
    "df_dummies['yr_mth'] = pd.to_datetime(df_dummies['time'], dayfirst=True).map(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "df_merged = pd.merge(df_dummies, disp_matxs, on=['yr_mth', 'admin1'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column with the sum of the displacements\n",
    "df_merged['sum_disp'] = df_merged.iloc[:, -18:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.to_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/csv/df_lags_2016_n4_disp_fd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for normalized data\n",
    "normalized_df = pd.DataFrame(columns=disp_matxs.columns)\n",
    "\n",
    "# Iterate through unique yr_mth values\n",
    "for yr_mth in disp_matxs['yr_mth'].unique():\n",
    "    # Select rows for the current yr_mth\n",
    "    subset = disp_matxs[disp_matxs['yr_mth'] == yr_mth].copy()\n",
    "    \n",
    "    # Extract the matrix values and convert to a NumPy array\n",
    "    matrix_values = subset.iloc[:, 1:-1].values\n",
    "    \n",
    "    # Perform normalization (e.g., min-max scaling)\n",
    "    min_val = np.min(matrix_values)\n",
    "    max_val = np.max(matrix_values)\n",
    "    normalized_matrix = (matrix_values - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Replace the original matrix with the normalized matrix\n",
    "    subset.iloc[:, 1:-1] = normalized_matrix\n",
    "    \n",
    "    # Append the modified subset to the new dataframe\n",
    "    normalized_df = pd.concat([normalized_df, subset])\n",
    "\n",
    "# Reset the index of the new dataframe\n",
    "normalized_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_aw=normalized_df[normalized_df['yr_mth']=='2016-01']\n",
    "w_aw = w_aw.drop(columns=['yr_mth', 'admin1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
