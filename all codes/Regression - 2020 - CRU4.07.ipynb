{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49af736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/.local/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40770/41488323.py:7: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices\n",
    "from collections import OrderedDict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ebf15",
   "metadata": {},
   "source": [
    "Data from UEA CRU TS4.07 (1901-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd212166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\cru_ts4.07.1901.2022.tmx.dat.nc\"\n",
    "# file2 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\cru_ts4.07.1901.2022.pre.dat.nc\"\n",
    "\n",
    "# file_paths_list =[file,file2]\n",
    "# monthly_forecast=xr.Dataset()\n",
    "\n",
    "# for file in file_paths_list:\n",
    "#         monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2646f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/cru_ts4.07.1901.2022.pre.dat.nc\"\n",
    "file2 = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/cru_ts4.07.1901.2022.tmx.dat.nc\"\n",
    "\n",
    "file_paths_list =[file,file2]\n",
    "monthly_forecast=xr.Dataset()\n",
    "\n",
    "for file in file_paths_list:\n",
    "        monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='override')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53f58",
   "metadata": {},
   "source": [
    "Data on conflict events from ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e1de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "# df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb3bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f32fa7",
   "metadata": {},
   "source": [
    "Shapefile with administrative boundaries of Somalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140d777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "# states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25cb8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/som_adm_ocha_itos_20230308_shp/som_admbnda_adm1_ocha_20230308.shp\"\n",
    "states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a83aa8",
   "metadata": {},
   "source": [
    "Limit the lat-lon and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ad81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(shp, world=True):\n",
    "    lon_lat = {}\n",
    "    # Get lat min, max\n",
    "    aoi_lat = [float(shp.total_bounds[1]), float(shp.total_bounds[3])]\n",
    "    aoi_lon = [float(shp.total_bounds[0]), float(shp.total_bounds[2])]\n",
    "\n",
    "    lon_lat[\"lon\"] = aoi_lon\n",
    "    lon_lat[\"lat\"] = aoi_lat\n",
    "    return lon_lat\n",
    "\n",
    "bounds = get_aoi(states_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e765a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1901-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "region = monthly_forecast[[\"pre\",'tmx']].sel(\n",
    "    time=slice(start_date, end_date),\n",
    "    lon=slice(bounds[\"lon\"][0], bounds[\"lon\"][1]),\n",
    "    lat=slice(bounds[\"lat\"][0], bounds[\"lat\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1382c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = regionmask.mask_3D_geopandas(states_gdf,\n",
    "                                         monthly_forecast.lon,\n",
    "                                         monthly_forecast.lat)\n",
    "\n",
    "temp_pre = region.where(region_mask)\n",
    "\n",
    "temp_pre = temp_pre.groupby(\"time\").mean([\"lat\", \"lon\"]).to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74921595",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {0  :  'Awdal',\n",
    "1    :         'Bakool',\n",
    "2      :       'Banadir',\n",
    "3      :         'Bari',\n",
    "4       :         'Bay',\n",
    "5        :  'Galgaduud',\n",
    "6          :      'Gedo',\n",
    "7          :   'Hiraan',\n",
    "8   :       'Lower_Juba',\n",
    "9   :   'Lower_Shabelle',\n",
    "10  :      'Middle_Juba',\n",
    "11   : 'Middle_Shabelle',\n",
    "12    :          'Mudug',\n",
    "13    :        'Nugaal',\n",
    "14      :       'Sanaag',\n",
    "15       :        'Sool',\n",
    "16        :   'Togdheer',\n",
    "17   : 'Woqooyi_Galbeed'}\n",
    "\n",
    "temp_pre['admin1'] = temp_pre['region'].replace(replacement_dict)\n",
    "df['admin1'] = df['admin1'].str.replace(' ', '_')\n",
    "temp_pre.drop('region', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f50e3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify event_date column to datetime\n",
    "\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df = df.set_index('event_date') \n",
    "\n",
    "conflict = df.groupby([pd.Grouper(freq='M'),\"admin1\"]).count()\n",
    "conflict.reset_index(level=[0, 1], inplace=True)\n",
    "conflict = conflict[['event_date','admin1','year']].rename(columns={'year': 'conflicts','event_date': 'time'})\n",
    "\n",
    "# Aggregate the datetime objects by month\n",
    "conf = conflict.groupby([pd.Grouper(key='time', freq='M'),'admin1'])['conflicts'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee086f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame with all dates and districts and fill missing values with 0\n",
    "\n",
    "dates = conf.index.get_level_values('time').unique()\n",
    "districts = conf.index.get_level_values('admin1').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts], names=['time', 'admin1'])\n",
    "\n",
    "conflicts = conf.reindex(all_combinations, fill_value=0).reset_index()    \n",
    "conflicts = conflicts.sort_values(by=['time', 'admin1'], ascending=[True, True])\n",
    "conflicts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8b312de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Banadir region with tmx and pre as mean of the neighbouring regions\n",
    "\n",
    "district1 = 'Lower_Shabelle'  \n",
    "district2 = 'Middle_Shabelle'  \n",
    "\n",
    "# Calculate the mean tmx and pre for the neighboring districts\n",
    "mean_t = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['tmx'].mean()\n",
    "mean_p = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['pre'].mean()\n",
    "\n",
    "new_data = pd.DataFrame({ 'admin1': 'Banadir', 'tmx': mean_t, 'pre': mean_p}).reset_index()\n",
    "\n",
    "# Append the new DataFrame to the original DataFrame\n",
    "df3 = pd.concat([temp_pre, new_data])\n",
    "\n",
    "temp_pre = df3.sort_values(by=['time', 'admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dbb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep month and year in time column in temp_pre and conflicts\n",
    "\n",
    "temp_pre['time'] = pd.to_datetime(temp_pre['time']).dt.strftime('%Y-%m-%d')\n",
    "temp_pre['month'] = temp_pre['time'].str[5:7]\n",
    "temp_pre['month_year'] = temp_pre['time'].str[:7]\n",
    "conflicts['time'] = conflicts['time'].dt.strftime('%Y-%m').values\n",
    "\n",
    "temp_pre = temp_pre[['month_year','admin1','tmx','pre']]\n",
    "temp_pre = temp_pre.rename(columns={'month_year':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a05554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into regions\n",
    "\n",
    "reg=[]\n",
    "for admin in temp_pre['admin1'].unique():\n",
    "    a = temp_pre[temp_pre['admin1']==admin].reset_index(drop=True)\n",
    "    reg.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80cdd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TA (temperature anomaly), PA (precipitation anomaly) and DL (drought lenght) for each region\n",
    "\n",
    "avg_t = avg_p = std_t = std_p = np.zeros(18)\n",
    "\n",
    "for i in range(18):\n",
    "\n",
    "    reg[i]['year'] , reg[i]['month'] = reg[i]['time'].str[:4] , reg[i]['time'].str[5:7]\n",
    "\n",
    "    # TA\n",
    "    mean_temp_i , std_temp_i  = reg[i].groupby('month')['tmx'].mean() , reg[i].groupby('month')['tmx'].std()\n",
    "    reg[i]['avg_temp'] , reg[i]['std_temp']  = reg[i]['month'].map(mean_temp_i) , reg[i]['month'].map(std_temp_i)\n",
    "    reg[i]['diff_t']= (reg[i]['tmx']-reg[i]['avg_temp'])/reg[i]['std_temp']\n",
    "    reg[i]['TA'] = (reg[i]['diff_t'].shift(3) + reg[i]['diff_t'].shift(2) + reg[i]['diff_t'].shift(1) + reg[i]['diff_t'])/4\n",
    "\n",
    "    # PA\n",
    "    mean_pre_i , std_pre_i  = reg[i].groupby('month')['pre'].mean() , reg[i].groupby('month')['pre'].std()\n",
    "    reg[i]['avg_pre'] , reg[i]['std_pre']= reg[i]['month'].map(mean_pre_i) , reg[i]['month'].map(std_pre_i)\n",
    "    reg[i]['diff_p']= (reg[i]['pre']-reg[i]['avg_pre'])/reg[i]['std_pre']\n",
    "    reg[i]['PA'] = (reg[i]['diff_p'].shift(3) + reg[i]['diff_p'].shift(2) + reg[i]['diff_p'].shift(1) + reg[i]['diff_p'])/4\n",
    "    \n",
    "    # DL \n",
    "    reg[i]['DL'] = 0\n",
    "    mask = reg[i]['TA'] > 0\n",
    "    group_id = (mask != mask.shift()).cumsum()             # Create a group identifier for each consecutive group\n",
    "    count = reg[i].groupby(group_id).cumcount() + 1        # Calculate the count within each group\n",
    "    reg[i]['DL'] = np.where(mask, count, 0)                # Assign the count values to the 'DL' column\n",
    "\n",
    "    # Add lagged variables\n",
    "    reg[i]['TA_lag1'] = reg[i]['TA'].shift(1)\n",
    "    reg[i]['PA_lag1'] = reg[i]['PA'].shift(1)\n",
    "    reg[i]['DL_lag1'] = reg[i]['DL'].shift(1)\n",
    "\n",
    "    #reg[i]['TA_lag1'], reg[i]['TA_lag2'], reg[i]['TA_lag3'], reg[i]['TA_lag4'], reg[i]['TA_lag5'], reg[i]['TA_lag6'] = reg[i]['TA'].shift(1), reg[i]['TA'].shift(2), reg[i]['TA'].shift(3), reg[i]['TA'].shift(4), reg[i]['TA'].shift(5), reg[i]['TA'].shift(6)\n",
    "    #reg[i]['PA_lag1'], reg[i]['PA_lag2'], reg[i]['PA_lag3'], reg[i]['PA_lag4'], reg[i]['PA_lag5'], reg[i]['PA_lag6'] = reg[i]['PA'].shift(1), reg[i]['PA'].shift(2), reg[i]['PA'].shift(3), reg[i]['PA'].shift(4), reg[i]['PA'].shift(5), reg[i]['PA'].shift(6)\n",
    "    #reg[i]['DL_lag1'], reg[i]['DL_lag2'], reg[i]['DL_lag3'], reg[i]['DL_lag4'], reg[i]['DL_lag5'], reg[i]['DL_lag6'] = reg[i]['DL'].shift(1), reg[i]['DL'].shift(2), reg[i]['DL'].shift(3), reg[i]['DL'].shift(4), reg[i]['DL'].shift(5), reg[i]['DL'].shift(6)\n",
    "\n",
    "    reg[i] = reg[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dd81ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre_c = pd.concat([reg[i] for i in range(18)], axis=0)\n",
    "temp_pre_c = temp_pre_c.dropna()\n",
    "\n",
    "# Select a subset of the dataframes from 1997-01 to 2009-12\n",
    "\n",
    "start='1997-01'\n",
    "end='2022-12'\n",
    "temp_pre_97_09 = temp_pre_c[(temp_pre_c['time'] >= start) & (temp_pre_c['time'] <= end)]\n",
    "conflicts_97_09 = conflicts[(conflicts['time'] >= start) & (conflicts['time'] <= end)]\n",
    "\n",
    "df_c_97_09 = pd.merge(temp_pre_97_09, conflicts_97_09, on=['time','admin1'], how='outer')\n",
    "df_c_97_09 = df_c_97_09.fillna(0)\n",
    "df_c_97_09 = df_c_97_09.drop(['avg_temp', 'avg_pre', 'std_temp', 'std_pre', 'diff_t', 'diff_p', 'tmx', 'pre'], axis=1)\n",
    "df_c_97_09 = df_c_97_09.sort_values(by=['time','admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d7743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummy variables\n",
    "\n",
    "#one for each country\n",
    "df_dummies = pd.get_dummies(df_c_97_09['admin1'])\n",
    "df_with_dummies = df_c_97_09.join(df_dummies)\n",
    "\n",
    "#one for each month\n",
    "df_c_97_09['month'] = pd.DatetimeIndex(df_c_97_09['time']).month_name()\n",
    "df_dummies_m = pd.get_dummies(df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_m)\n",
    "df_with_dummies['month'] = pd.DatetimeIndex(df_c_97_09['time']).month\n",
    "\n",
    "#create a dictionary where the keys are increasing integers and the values are the values of the time column\n",
    "time_dict = dict(enumerate(df_c_97_09['time'].unique(), 25))\n",
    "inv_time_dict = {v: k for k, v in time_dict.items()}\n",
    "\n",
    "#create a new variable for the month_year column\n",
    "df_c_97_09['time'].replace(inv_time_dict, inplace=True)\n",
    "#add a string before the number \n",
    "df_c_97_09['time'] = 'yrmth_' + df_c_97_09['time'].astype(str)\n",
    "\n",
    "#df_dummies_new = pd.get_dummies(df_c_97_09['time'])\n",
    "#df_with_dummies = df_with_dummies.join(df_dummies_new)\n",
    "df_with_dummies = df_with_dummies.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e81561e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6:'June', 7:'July', 8:'August', 9:'September', 10:'October', 11:'November', 12:'December'}\n",
    "df_with_dummies['month_name'] = df_with_dummies['month'].map(month_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0888b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_name = 'conflicts'\n",
    "X_var_names = ['TA_lag1','PA_lag1','DL_lag1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a893f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression expression for OLS with dummies=conflicts ~ TA_lag1 + PA_lag1 + DL_lag1 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n"
     ]
    }
   ],
   "source": [
    "# Regression expression for OLS with dummies\n",
    "\n",
    "unit_names = df_c_97_09['admin1'].unique().tolist()\n",
    "unit_names.sort()\n",
    "unit_names_t = df_c_97_09['month'].unique().tolist()\n",
    "unit_names_my = df_c_97_09['time'].astype(str).unique().tolist()\n",
    "unit_names_mr = (df_c_97_09['admin1'] + df_c_97_09['month']).unique().tolist()\n",
    "unit_names_myr = (df_c_97_09['admin1'] + df_c_97_09['time'].astype(str)).unique().tolist()\n",
    "\n",
    "lsdv_expr = y_var_name + ' ~ '\n",
    "i = 0\n",
    "for X_var_name in X_var_names:\n",
    "    if i > 0:\n",
    "        lsdv_expr = lsdv_expr + ' + ' + X_var_name\n",
    "    else:\n",
    "        lsdv_expr = lsdv_expr + X_var_name\n",
    "    i = i + 1\n",
    "for dummy_name in unit_names[:-1]:\n",
    "   lsdv_expr = lsdv_expr + ' + ' + dummy_name\n",
    "for dummy_name_t in unit_names_t[:-1]:\n",
    "    lsdv_expr = lsdv_expr + ' + ' + dummy_name_t\n",
    "#for dummy_name_mr in unit_names_my[:-1]:\n",
    "    #lsdv_expr = lsdv_expr + ' + ' + dummy_name_mr\n",
    "#lsdv_expr = lsdv_expr + ' - ' + '1'\n",
    "print('Regression expression for OLS with dummies=' + lsdv_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9af6641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.473\n",
      "Model:                            OLS   Adj. R-squared:                  0.470\n",
      "Method:                 Least Squares   F-statistic:                     161.4\n",
      "Date:                Tue, 26 Sep 2023   Prob (F-statistic):               0.00\n",
      "Time:                        16:06:01   Log-Likelihood:                -20816.\n",
      "No. Observations:                5616   AIC:                         4.170e+04\n",
      "Df Residuals:                    5584   BIC:                         4.191e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          -2.2386      0.736     -3.042      0.002      -3.681      -0.796\n",
      "TA_lag1             1.5867      0.262      6.053      0.000       1.073       2.101\n",
      "PA_lag1             0.9408      0.476      1.975      0.048       0.007       1.875\n",
      "DL_lag1             0.1205      0.005     23.211      0.000       0.110       0.131\n",
      "Awdal              -4.2003      0.800     -5.250      0.000      -5.769      -2.632\n",
      "Bakool              2.1671      0.795      2.726      0.006       0.609       3.726\n",
      "Banadir            36.2469      0.799     45.393      0.000      34.681      37.812\n",
      "Bari                4.5892      0.796      5.765      0.000       3.029       6.150\n",
      "Bay                 7.0583      0.794      8.887      0.000       5.501       8.615\n",
      "Galgaduud           5.8538      0.806      7.260      0.000       4.273       7.434\n",
      "Gedo                2.0734      0.798      2.599      0.009       0.510       3.637\n",
      "Hiraan              9.0328      0.801     11.279      0.000       7.463      10.603\n",
      "Lower_Juba          5.2354      0.806      6.494      0.000       3.655       6.816\n",
      "Lower_Shabelle     19.9319      0.795     25.083      0.000      18.374      21.490\n",
      "Middle_Juba        -4.1493      0.807     -5.145      0.000      -5.730      -2.568\n",
      "Middle_Shabelle     8.1185      0.808     10.052      0.000       6.535       9.702\n",
      "Mudug               6.4325      0.807      7.974      0.000       4.851       8.014\n",
      "Nugaal              2.6186      0.803      3.262      0.001       1.045       4.192\n",
      "Sanaag              1.4961      0.794      1.885      0.060      -0.060       3.052\n",
      "Sool                2.5825      0.796      3.246      0.001       1.023       4.142\n",
      "Togdheer            1.6237      0.793      2.047      0.041       0.069       3.179\n",
      "January            -0.4081      0.646     -0.632      0.528      -1.675       0.859\n",
      "February           -0.4866      0.646     -0.753      0.451      -1.753       0.780\n",
      "March              -0.4914      0.646     -0.761      0.447      -1.758       0.775\n",
      "April              -0.8255      0.646     -1.277      0.202      -2.093       0.442\n",
      "May                -0.2322      0.646     -0.359      0.719      -1.499       1.035\n",
      "June                0.0582      0.646      0.090      0.928      -1.209       1.325\n",
      "July                0.1926      0.647      0.298      0.766      -1.075       1.460\n",
      "August              0.1878      0.647      0.290      0.772      -1.080       1.455\n",
      "September          -0.5673      0.647     -0.877      0.381      -1.835       0.701\n",
      "October            -0.3394      0.647     -0.524      0.600      -1.609       0.930\n",
      "November           -0.5185      0.646     -0.803      0.422      -1.785       0.748\n",
      "==============================================================================\n",
      "Omnibus:                     1955.190   Durbin-Watson:                   1.791\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            24429.933\n",
      "Skew:                           1.304   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.879   Cond. No.                         739.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lsdv_model = smf.ols(formula=lsdv_expr, data=df_with_dummies)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "print(lsdv_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0178cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_dummies.to_csv(r'/home/sara/Documenti/GitHub/Climate-and-conflict/df_lag1.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c82327b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC = 41695.05832518947\n"
     ]
    }
   ],
   "source": [
    "#compute AIC\n",
    "print('AIC = ' + str(lsdv_model_results.aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a994ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\dist_som.csv\")\n",
    "dist = pd.read_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/dist_som.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78de8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dist = 1/(dist+0.001)\n",
    "inv_dist.reset_index(inplace=True)\n",
    "inv_dist['index'] = inv_dist['index'].replace(replacement_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5037a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new=df_with_dummies.merge(inv_dist, left_on='admin1', right_on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d3d5291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations to be tested: 125\n"
     ]
    }
   ],
   "source": [
    "lag_combinations = OrderedDict()\n",
    " \n",
    "for combination in itertools.product(range(1,6), repeat=3):\n",
    "        lag_combinations[combination] = 0.0\n",
    " \n",
    "print('Number of combinations to be tested: ' + str(len(lag_combinations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5880adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for expr: conflicts ~ TA_lag1 + PA_lag1 + DL_lag1 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n",
      "(1, 1, 1)\n",
      "AIC=41695.05832518947\n",
      "Building model for expr: conflicts ~ TA_lag1 + PA_lag1 + DL_lag2 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n",
      "(1, 1, 2)\n"
     ]
    },
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'DL_lag2' is not defined\n    conflicts ~ TA_lag1 + PA_lag1 + DL_lag2 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n                                    ^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/compat.py:36\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     37\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/eval.py:169\u001b[0m, in \u001b[0;36mEvalEnvironment.eval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    168\u001b[0m code \u001b[39m=\u001b[39m \u001b[39mcompile\u001b[39m(expr, source_name, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflags, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39meval\u001b[39;49m(code, {}, VarLookupDict([inner_namespace]\n\u001b[1;32m    170\u001b[0m                                     \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_namespaces))\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DL_lag2' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sara/Documenti/GitHub/Climate-and-conflict/all codes/Regression - 2020 - CRU4.07.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X45sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(combination)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X45sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#Carve out the X,y vectors using patsy. We will use X_test, y_test later for testing the model.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X45sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m y_test, X_test \u001b[39m=\u001b[39m dmatrices(expr, df_with_dummies, return_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdataframe\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X45sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#Build and train the OLSR model on the training data set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X45sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m olsr_results \u001b[39m=\u001b[39m smf\u001b[39m.\u001b[39mols(expr, df_with_dummies)\u001b[39m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/highlevel.py:309\u001b[0m, in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[39mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m eval_env \u001b[39m=\u001b[39m EvalEnvironment\u001b[39m.\u001b[39mcapture(eval_env, reference\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m (lhs, rhs) \u001b[39m=\u001b[39m _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m    310\u001b[0m                                   NA_action, return_type)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m lhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m PatsyError(\u001b[39m\"\u001b[39m\u001b[39mmodel is missing required outcome variables\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_iter_maker\u001b[39m():\n\u001b[1;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m([data])\n\u001b[0;32m--> 164\u001b[0m design_infos \u001b[39m=\u001b[39m _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m    165\u001b[0m                                   NA_action)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m design_infos \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m build_design_matrices(design_infos, data,\n\u001b[1;32m    168\u001b[0m                                  NA_action\u001b[39m=\u001b[39mNA_action,\n\u001b[1;32m    169\u001b[0m                                  return_type\u001b[39m=\u001b[39mreturn_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/highlevel.py:66\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[1;32m     65\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m design_matrix_builders([formula_like\u001b[39m.\u001b[39;49mlhs_termlist,\n\u001b[1;32m     67\u001b[0m                                    formula_like\u001b[39m.\u001b[39;49mrhs_termlist],\n\u001b[1;32m     68\u001b[0m                                   data_iter_maker,\n\u001b[1;32m     69\u001b[0m                                   eval_env,\n\u001b[1;32m     70\u001b[0m                                   NA_action)\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/build.py:693\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    689\u001b[0m factor_states \u001b[39m=\u001b[39m _factors_memorize(all_factors, data_iter_maker, eval_env)\n\u001b[1;32m    690\u001b[0m \u001b[39m# Now all the factors have working eval methods, so we can evaluate them\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39m# on some data to find out what type of data they return.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m (num_column_counts,\n\u001b[0;32m--> 693\u001b[0m  cat_levels_contrasts) \u001b[39m=\u001b[39m _examine_factor_types(all_factors,\n\u001b[1;32m    694\u001b[0m                                                factor_states,\n\u001b[1;32m    695\u001b[0m                                                data_iter_maker,\n\u001b[1;32m    696\u001b[0m                                                NA_action)\n\u001b[1;32m    697\u001b[0m \u001b[39m# Now we need the factor infos, which encapsulate the knowledge of\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39m# how to turn any given factor into a chunk of data:\u001b[39;00m\n\u001b[1;32m    699\u001b[0m factor_infos \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/build.py:443\u001b[0m, in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m data_iter_maker():\n\u001b[1;32m    442\u001b[0m     \u001b[39mfor\u001b[39;00m factor \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(examine_needed):\n\u001b[0;32m--> 443\u001b[0m         value \u001b[39m=\u001b[39m factor\u001b[39m.\u001b[39;49meval(factor_states[factor], data)\n\u001b[1;32m    444\u001b[0m         \u001b[39mif\u001b[39;00m factor \u001b[39min\u001b[39;00m cat_sniffers \u001b[39mor\u001b[39;00m guess_categorical(value):\n\u001b[1;32m    445\u001b[0m             \u001b[39mif\u001b[39;00m factor \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m cat_sniffers:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/eval.py:568\u001b[0m, in \u001b[0;36mEvalFactor.eval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, memorize_state, data):\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval(memorize_state[\u001b[39m\"\u001b[39;49m\u001b[39meval_code\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    569\u001b[0m                       memorize_state,\n\u001b[1;32m    570\u001b[0m                       data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/eval.py:551\u001b[0m, in \u001b[0;36mEvalFactor._eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_eval\u001b[39m(\u001b[39mself\u001b[39m, code, memorize_state, data):\n\u001b[1;32m    550\u001b[0m     inner_namespace \u001b[39m=\u001b[39m VarLookupDict([data, memorize_state[\u001b[39m\"\u001b[39m\u001b[39mtransforms\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[0;32m--> 551\u001b[0m     \u001b[39mreturn\u001b[39;00m call_and_wrap_exc(\u001b[39m\"\u001b[39;49m\u001b[39mError evaluating factor\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    552\u001b[0m                              \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    553\u001b[0m                              memorize_state[\u001b[39m\"\u001b[39;49m\u001b[39meval_env\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49meval,\n\u001b[1;32m    554\u001b[0m                              code,\n\u001b[1;32m    555\u001b[0m                              inner_namespace\u001b[39m=\u001b[39;49minner_namespace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/compat.py:43\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     new_exc \u001b[39m=\u001b[39m PatsyError(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m                          \u001b[39m%\u001b[39m (msg, e\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, e),\n\u001b[1;32m     41\u001b[0m                          origin)\n\u001b[1;32m     42\u001b[0m     \u001b[39m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     exec(\u001b[39m\"\u001b[39;49m\u001b[39mraise new_exc from e\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[39m# In python 2, we just let the original exception escape -- better\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[39m# than destroying the traceback. But if it's a PatsyError, we can\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39m# at least set the origin properly.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, PatsyError):\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'DL_lag2' is not defined\n    conflicts ~ TA_lag1 + PA_lag1 + DL_lag2 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n                                    ^^^^^^^"
     ]
    }
   ],
   "source": [
    "X_var_ = ['TA_','PA_','DL_']\n",
    "expr_prefix = 'conflicts ~ '\n",
    " \n",
    "min_aic = sys.float_info.max\n",
    "best_expr = ''\n",
    "best_olsr_model_results = None\n",
    " \n",
    "#Iterate over each combination\n",
    "for combination in lag_combinations:\n",
    "    expr = expr_prefix\n",
    "    i = 1\n",
    "    #Setup the model expression using patsy syntax\n",
    "    for i, lag_num in enumerate(combination):\n",
    "        if i < len(combination)-1:\n",
    "            expr = expr  + X_var_[i] + 'lag' + str(lag_num) + ' + '\n",
    "        else:\n",
    "            expr = expr + X_var_[i] + 'lag' + str(lag_num)\n",
    " \n",
    "        i += 1\n",
    "    for dummy_name in unit_names[:-1]:\n",
    "        expr = expr + ' + ' + dummy_name\n",
    "    for dummy_name_t in unit_names_t[:-1]:\n",
    "        expr = expr + ' + ' + dummy_name_t\n",
    " \n",
    "    print('Building model for expr: ' + expr)\n",
    "    print(combination)\n",
    "\n",
    "    #Carve out the X,y vectors using patsy. We will use X_test, y_test later for testing the model.\n",
    "    y_test, X_test = dmatrices(expr, df_with_dummies, return_type='dataframe')\n",
    " \n",
    "    #Build and train the OLSR model on the training data set\n",
    "    olsr_results = smf.ols(expr, df_with_dummies).fit()\n",
    " \n",
    "    #Store it's AIC value\n",
    "    lag_combinations[combination] = olsr_results.aic\n",
    " \n",
    "    #Keep track of the best model (the one with the lowest AIC score) seen so far\n",
    "    if olsr_results.aic < min_aic:\n",
    "        min_aic = olsr_results.aic\n",
    "        best_expr = expr\n",
    "        best_olsr_model_results = olsr_results\n",
    " \n",
    "    print('AIC='+str(lag_combinations[combination]))\n",
    "\n",
    "print(best_olsr_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.822\n",
      "Model:                            OLS   Adj. R-squared:                  0.818\n",
      "Method:                 Least Squares   F-statistic:                     219.9\n",
      "Date:                Thu, 21 Sep 2023   Prob (F-statistic):               0.00\n",
      "Time:                        10:41:48   Log-Likelihood:                -5146.0\n",
      "No. Observations:                1512   AIC:                         1.036e+04\n",
      "Df Residuals:                    1480   BIC:                         1.053e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           3.1659      1.077      2.939      0.003       1.053       5.279\n",
      "TA_lag3             0.5207      0.339      1.534      0.125      -0.145       1.186\n",
      "PA_lag1            -1.4791      0.649     -2.278      0.023      -2.753      -0.205\n",
      "DL_lag5             0.0149      0.007      2.217      0.027       0.002       0.028\n",
      "Awdal              -2.3776      1.176     -2.022      0.043      -4.685      -0.071\n",
      "Bakool              4.5128      1.145      3.943      0.000       2.268       6.758\n",
      "Banadir            52.1009      1.143     45.582      0.000      49.859      54.343\n",
      "Bari                6.7858      1.144      5.931      0.000       4.541       9.030\n",
      "Bay                14.7974      1.148     12.893      0.000      12.546      17.049\n",
      "Galgaduud           6.0745      1.164      5.220      0.000       3.792       8.357\n",
      "Gedo                7.4138      1.150      6.449      0.000       5.159       9.669\n",
      "Hiraan             15.2773      1.149     13.296      0.000      13.024      17.531\n",
      "Lower_Juba         20.2440      1.310     15.453      0.000      17.674      22.814\n",
      "Lower_Shabelle     50.2113      1.147     43.781      0.000      47.962      52.461\n",
      "Middle_Juba        -1.2086      1.305     -0.926      0.355      -3.769       1.352\n",
      "Middle_Shabelle    15.8803      1.162     13.667      0.000      13.601      18.160\n",
      "Mudug               6.4391      1.165      5.526      0.000       4.153       8.725\n",
      "Nugaal              0.2030      1.157      0.175      0.861      -2.066       2.472\n",
      "Sanaag              0.2983      1.136      0.263      0.793      -1.931       2.527\n",
      "Sool                1.2822      1.140      1.125      0.261      -0.954       3.518\n",
      "Togdheer            0.4417      1.136      0.389      0.697      -1.786       2.670\n",
      "January            -1.4963      0.928     -1.613      0.107      -3.316       0.324\n",
      "February           -1.5116      0.928     -1.629      0.104      -3.332       0.309\n",
      "March              -2.2928      0.928     -2.471      0.014      -4.113      -0.473\n",
      "April              -2.0026      0.929     -2.156      0.031      -3.824      -0.181\n",
      "May                -0.8572      0.927     -0.924      0.355      -2.676       0.962\n",
      "June               -1.0531      0.927     -1.136      0.256      -2.872       0.766\n",
      "July               -2.4226      0.927     -2.612      0.009      -4.242      -0.604\n",
      "August             -0.6364      0.929     -0.685      0.494      -2.459       1.186\n",
      "September          -0.4135      0.929     -0.445      0.656      -2.235       1.408\n",
      "October            -0.5754      0.930     -0.619      0.536      -2.399       1.249\n",
      "November           -1.3589      0.927     -1.466      0.143      -3.177       0.459\n",
      "==============================================================================\n",
      "Omnibus:                      549.439   Durbin-Watson:                   1.752\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5168.789\n",
      "Skew:                           1.421   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.600   Cond. No.                     1.15e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.15e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(best_olsr_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74eb41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
