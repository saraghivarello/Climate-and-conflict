{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49af736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices\n",
    "from collections import OrderedDict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ebf15",
   "metadata": {},
   "source": [
    "Data from UEA CRU TS4.07 (1901-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2646f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\cru_ts4.07.1901.2022.tmx.dat.nc\"\n",
    "file2 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\cru_ts4.07.1901.2022.pre.dat.nc\"\n",
    "#file = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/cru_ts4.07.1901.2022.pre.dat.nc\"\n",
    "#file2 = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/cru_ts4.07.1901.2022.tmx.dat.nc\"\n",
    "\n",
    "file_paths_list =[file,file2]\n",
    "monthly_forecast=xr.Dataset()\n",
    "\n",
    "for file in file_paths_list:\n",
    "        monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='override')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53f58",
   "metadata": {},
   "source": [
    "Data on conflict events from ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffb3bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\ACLED_1997-01-01-2023-07-18_Somalia.csv\"# df = pd.read_csv(file)\n",
    "#file = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f32fa7",
   "metadata": {},
   "source": [
    "Shapefile with administrative boundaries of Somalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25cb8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "#path = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/som_adm_ocha_itos_20230308_shp/som_admbnda_adm1_ocha_20230308.shp\"\n",
    "states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a83aa8",
   "metadata": {},
   "source": [
    "Limit the lat-lon and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4ad81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(shp, world=True):\n",
    "    lon_lat = {}\n",
    "    # Get lat min, max\n",
    "    aoi_lat = [float(shp.total_bounds[1]), float(shp.total_bounds[3])]\n",
    "    aoi_lon = [float(shp.total_bounds[0]), float(shp.total_bounds[2])]\n",
    "\n",
    "    lon_lat[\"lon\"] = aoi_lon\n",
    "    lon_lat[\"lat\"] = aoi_lat\n",
    "    return lon_lat\n",
    "\n",
    "bounds = get_aoi(states_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e765a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1901-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "region = monthly_forecast[[\"pre\",'tmx']].sel(\n",
    "    time=slice(start_date, end_date),\n",
    "    lon=slice(bounds[\"lon\"][0], bounds[\"lon\"][1]),\n",
    "    lat=slice(bounds[\"lat\"][0], bounds[\"lat\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1382c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = regionmask.mask_3D_geopandas(states_gdf,\n",
    "                                         monthly_forecast.lon,\n",
    "                                         monthly_forecast.lat)\n",
    "\n",
    "temp_pre = region.where(region_mask)\n",
    "\n",
    "temp_pre = temp_pre.groupby(\"time\").mean([\"lat\", \"lon\"]).to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "74921595",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {0  :  'Awdal',\n",
    "1    :         'Bakool',\n",
    "2      :       'Banadir',\n",
    "3      :         'Bari',\n",
    "4       :         'Bay',\n",
    "5        :  'Galgaduud',\n",
    "6          :      'Gedo',\n",
    "7          :   'Hiraan',\n",
    "8   :       'Lower_Juba',\n",
    "9   :   'Lower_Shabelle',\n",
    "10  :      'Middle_Juba',\n",
    "11   : 'Middle_Shabelle',\n",
    "12    :          'Mudug',\n",
    "13    :        'Nugaal',\n",
    "14      :       'Sanaag',\n",
    "15       :        'Sool',\n",
    "16        :   'Togdheer',\n",
    "17   : 'Woqooyi_Galbeed'}\n",
    "\n",
    "temp_pre['admin1'] = temp_pre['region'].replace(replacement_dict)\n",
    "df['admin1'] = df['admin1'].str.replace(' ', '_')\n",
    "temp_pre.drop('region', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f50e3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify event_date column to datetime\n",
    "\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df = df.set_index('event_date') \n",
    "\n",
    "conflict = df.groupby([pd.Grouper(freq='M'),\"admin1\"]).count()\n",
    "conflict.reset_index(level=[0, 1], inplace=True)\n",
    "conflict = conflict[['event_date','admin1','year']].rename(columns={'year': 'conflicts','event_date': 'time'})\n",
    "\n",
    "# Aggregate the datetime objects by month\n",
    "conf = conflict.groupby([pd.Grouper(key='time', freq='M'),'admin1'])['conflicts'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee086f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame with all dates and districts and fill missing values with 0\n",
    "\n",
    "dates = conf.index.get_level_values('time').unique()\n",
    "districts = conf.index.get_level_values('admin1').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts], names=['time', 'admin1'])\n",
    "\n",
    "conflicts = conf.reindex(all_combinations, fill_value=0).reset_index()    \n",
    "conflicts = conflicts.sort_values(by=['time', 'admin1'], ascending=[True, True])\n",
    "conflicts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8b312de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Banadir region with tmx and pre as mean of the neighbouring regions\n",
    "\n",
    "district1 = 'Lower_Shabelle'  \n",
    "district2 = 'Middle_Shabelle'  \n",
    "\n",
    "# Calculate the mean tmx and pre for the neighboring districts\n",
    "mean_t = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['tmx'].mean()\n",
    "mean_p = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['pre'].mean()\n",
    "\n",
    "new_data = pd.DataFrame({ 'admin1': 'Banadir', 'tmx': mean_t, 'pre': mean_p}).reset_index()\n",
    "\n",
    "# Append the new DataFrame to the original DataFrame\n",
    "df3 = pd.concat([temp_pre, new_data])\n",
    "\n",
    "temp_pre = df3.sort_values(by=['time', 'admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7dbb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep month and year in time column in temp_pre and conflicts\n",
    "\n",
    "temp_pre['time'] = pd.to_datetime(temp_pre['time']).dt.strftime('%Y-%m-%d')\n",
    "temp_pre['month'] = temp_pre['time'].str[5:7]\n",
    "temp_pre['month_year'] = temp_pre['time'].str[:7]\n",
    "conflicts['time'] = conflicts['time'].dt.strftime('%Y-%m').values\n",
    "\n",
    "temp_pre = temp_pre[['month_year','admin1','tmx','pre']]\n",
    "temp_pre = temp_pre.rename(columns={'month_year':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4a05554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into regions\n",
    "\n",
    "reg=[]\n",
    "for admin in temp_pre['admin1'].unique():\n",
    "    a = temp_pre[temp_pre['admin1']==admin].reset_index(drop=True)\n",
    "    reg.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80cdd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TA (temperature anomaly), PA (precipitation anomaly) and DL (drought lenght) for each region\n",
    "\n",
    "avg_t = avg_p = std_t = std_p = np.zeros(18)\n",
    "\n",
    "for i in range(18):\n",
    "\n",
    "    reg[i]['year'] , reg[i]['month'] = reg[i]['time'].str[:4] , reg[i]['time'].str[5:7]\n",
    "\n",
    "    # TA\n",
    "    mean_temp_i , std_temp_i  = reg[i].groupby('month')['tmx'].mean() , reg[i].groupby('month')['tmx'].std()\n",
    "    reg[i]['avg_temp'] , reg[i]['std_temp']  = reg[i]['month'].map(mean_temp_i) , reg[i]['month'].map(std_temp_i)\n",
    "    reg[i]['diff_t']= (reg[i]['tmx']-reg[i]['avg_temp'])/reg[i]['std_temp']\n",
    "    reg[i]['TA'] = (reg[i]['diff_t'].shift(3) + reg[i]['diff_t'].shift(2) + reg[i]['diff_t'].shift(1) + reg[i]['diff_t'])/4\n",
    "\n",
    "    # PA\n",
    "    mean_pre_i , std_pre_i  = reg[i].groupby('month')['pre'].mean() , reg[i].groupby('month')['pre'].std()\n",
    "    reg[i]['avg_pre'] , reg[i]['std_pre']= reg[i]['month'].map(mean_pre_i) , reg[i]['month'].map(std_pre_i)\n",
    "    reg[i]['diff_p']= (reg[i]['pre']-reg[i]['avg_pre'])/reg[i]['std_pre']\n",
    "    reg[i]['PA'] = (reg[i]['diff_p'].shift(3) + reg[i]['diff_p'].shift(2) + reg[i]['diff_p'].shift(1) + reg[i]['diff_p'])/4\n",
    "    \n",
    "    # DL \n",
    "    reg[i]['DL'] = 0\n",
    "    mask = reg[i]['TA'] > 0\n",
    "    group_id = (mask != mask.shift()).cumsum()             # Create a group identifier for each consecutive group\n",
    "    count = reg[i].groupby(group_id).cumcount() + 1        # Calculate the count within each group\n",
    "    reg[i]['DL'] = np.where(mask, count, 0)                # Assign the count values to the 'DL' column\n",
    "\n",
    "    # Add lagged variables\n",
    "    reg[i]['TA_lag1'] = reg[i]['TA'].shift(1)\n",
    "    reg[i]['PA_lag1'] = reg[i]['PA'].shift(1)\n",
    "    reg[i]['DL_lag1'] = reg[i]['DL'].shift(1)\n",
    "\n",
    "    #reg[i]['TA_lag1'], reg[i]['TA_lag2'], reg[i]['TA_lag3'], reg[i]['TA_lag4'], reg[i]['TA_lag5'], reg[i]['TA_lag6'] = reg[i]['TA'].shift(1), reg[i]['TA'].shift(2), reg[i]['TA'].shift(3), reg[i]['TA'].shift(4), reg[i]['TA'].shift(5), reg[i]['TA'].shift(6)\n",
    "    #reg[i]['PA_lag1'], reg[i]['PA_lag2'], reg[i]['PA_lag3'], reg[i]['PA_lag4'], reg[i]['PA_lag5'], reg[i]['PA_lag6'] = reg[i]['PA'].shift(1), reg[i]['PA'].shift(2), reg[i]['PA'].shift(3), reg[i]['PA'].shift(4), reg[i]['PA'].shift(5), reg[i]['PA'].shift(6)\n",
    "    #reg[i]['DL_lag1'], reg[i]['DL_lag2'], reg[i]['DL_lag3'], reg[i]['DL_lag4'], reg[i]['DL_lag5'], reg[i]['DL_lag6'] = reg[i]['DL'].shift(1), reg[i]['DL'].shift(2), reg[i]['DL'].shift(3), reg[i]['DL'].shift(4), reg[i]['DL'].shift(5), reg[i]['DL'].shift(6)\n",
    "\n",
    "    reg[i] = reg[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3dd81ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre_c = pd.concat([reg[i] for i in range(18)], axis=0)\n",
    "temp_pre_c = temp_pre_c.dropna()\n",
    "\n",
    "# Select a subset of the dataframes from 1997-01 to 2022-12\n",
    "\n",
    "start='2016-01'\n",
    "end='2022-12'\n",
    "temp_pre_16_22 = temp_pre_c[(temp_pre_c['time'] >= start) & (temp_pre_c['time'] <= end)]\n",
    "conflicts_16_22 = conflicts[(conflicts['time'] >= start) & (conflicts['time'] <= end)]\n",
    "\n",
    "df_2016 = pd.merge(temp_pre_16_22, conflicts_16_22, on=['time','admin1'], how='outer')\n",
    "df_2016 = df_2016.fillna(0)\n",
    "df_2016 = df_2016.drop(['avg_temp', 'avg_pre', 'std_temp', 'std_pre', 'diff_t', 'diff_p', 'tmx', 'pre'], axis=1)\n",
    "df_2016 = df_2016.sort_values(by=['time','admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1d7743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummy variables\n",
    "\n",
    "#one for each country\n",
    "df_dummies = pd.get_dummies(df_2016['admin1'])\n",
    "df_with_dummies = df_2016.join(df_dummies)\n",
    "\n",
    "#one for each month\n",
    "df_2016['month'] = pd.DatetimeIndex(df_2016['time']).month_name()\n",
    "df_dummies_m = pd.get_dummies(df_2016['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_m)\n",
    "df_with_dummies['month'] = pd.DatetimeIndex(df_2016['time']).month\n",
    "\n",
    "#create a dictionary where the keys are increasing integers and the values are the values of the time column\n",
    "time_dict = dict(enumerate(df_2016['time'].unique(), 25))\n",
    "inv_time_dict = {v: k for k, v in time_dict.items()}\n",
    "\n",
    "#create a new variable for the month_year column\n",
    "df_2016['time'].replace(inv_time_dict, inplace=True)\n",
    "#add a string before the number \n",
    "df_2016['time'] = 'yrmth_' + df_2016['time'].astype(str)\n",
    "\n",
    "#df_dummies_new = pd.get_dummies(df_2016['time'])\n",
    "#df_with_dummies = df_with_dummies.join(df_dummies_new)\n",
    "df_with_dummies = df_with_dummies.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e81561e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6:'June', 7:'July', 8:'August', 9:'September', 10:'October', 11:'November', 12:'December'}\n",
    "df_with_dummies['month_name'] = df_with_dummies['month'].map(month_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d0888b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_name = 'conflicts'\n",
    "X_var_names = ['TA_lag1','PA_lag1','DL_lag1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a893f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression expression for OLS with dummies=conflicts ~ TA_lag1 + PA_lag1 + DL_lag1 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n"
     ]
    }
   ],
   "source": [
    "# Regression expression for OLS with dummies\n",
    "\n",
    "unit_names = df_2016['admin1'].unique().tolist()\n",
    "unit_names.sort()\n",
    "unit_names_t = df_2016['month'].unique().tolist()\n",
    "unit_names_my = df_2016['time'].astype(str).unique().tolist()\n",
    "unit_names_mr = (df_2016['admin1'] + df_2016['month']).unique().tolist()\n",
    "unit_names_myr = (df_2016['admin1'] + df_2016['time'].astype(str)).unique().tolist()\n",
    "\n",
    "lsdv_expr = y_var_name + ' ~ '\n",
    "i = 0\n",
    "for X_var_name in X_var_names:\n",
    "    if i > 0:\n",
    "        lsdv_expr = lsdv_expr + ' + ' + X_var_name\n",
    "    else:\n",
    "        lsdv_expr = lsdv_expr + X_var_name\n",
    "    i = i + 1\n",
    "for dummy_name in unit_names[:-1]:\n",
    "   lsdv_expr = lsdv_expr + ' + ' + dummy_name\n",
    "for dummy_name_t in unit_names_t[:-1]:\n",
    "    lsdv_expr = lsdv_expr + ' + ' + dummy_name_t\n",
    "#for dummy_name_mr in unit_names_my[:-1]:\n",
    "    #lsdv_expr = lsdv_expr + ' + ' + dummy_name_mr\n",
    "#lsdv_expr = lsdv_expr + ' - ' + '1'\n",
    "print('Regression expression for OLS with dummies=' + lsdv_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9af6641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.821\n",
      "Model:                            OLS   Adj. R-squared:                  0.817\n",
      "Method:                 Least Squares   F-statistic:                     219.3\n",
      "Date:                Mon, 23 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:16:45   Log-Likelihood:                -5147.8\n",
      "No. Observations:                1512   AIC:                         1.036e+04\n",
      "Df Residuals:                    1480   BIC:                         1.053e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           3.4296      1.074      3.192      0.001       1.322       5.537\n",
      "TA_lag1             0.3420      0.364      0.939      0.348      -0.373       1.057\n",
      "PA_lag1            -1.5589      0.653     -2.388      0.017      -2.840      -0.278\n",
      "DL_lag1             0.0115      0.007      1.683      0.093      -0.002       0.025\n",
      "Awdal              -2.1926      1.175     -1.866      0.062      -4.497       0.112\n",
      "Bakool              4.5523      1.145      3.975      0.000       2.306       6.799\n",
      "Banadir            51.9651      1.143     45.459      0.000      49.723      54.207\n",
      "Bari                6.7497      1.145      5.893      0.000       4.503       8.996\n",
      "Bay                14.8812      1.148     12.958      0.000      12.628      17.134\n",
      "Galgaduud           5.8788      1.165      5.048      0.000       3.595       8.163\n",
      "Gedo                7.5166      1.150      6.537      0.000       5.261       9.772\n",
      "Hiraan             15.1602      1.151     13.173      0.000      12.903      17.418\n",
      "Lower_Juba         20.5664      1.326     15.516      0.000      17.966      23.167\n",
      "Lower_Shabelle     50.2737      1.148     43.801      0.000      48.022      52.525\n",
      "Middle_Juba        -0.9093      1.324     -0.686      0.493      -3.507       1.689\n",
      "Middle_Shabelle    15.6816      1.162     13.493      0.000      13.402      17.961\n",
      "Mudug               6.2386      1.166      5.349      0.000       3.951       8.526\n",
      "Nugaal              0.0404      1.158      0.035      0.972      -2.231       2.312\n",
      "Sanaag              0.2668      1.138      0.235      0.815      -1.965       2.498\n",
      "Sool                1.2142      1.142      1.064      0.288      -1.025       3.454\n",
      "Togdheer            0.4020      1.137      0.353      0.724      -1.829       2.633\n",
      "January            -1.4577      0.930     -1.568      0.117      -3.281       0.366\n",
      "February           -1.4440      0.929     -1.555      0.120      -3.266       0.378\n",
      "March              -2.2211      0.928     -2.393      0.017      -4.042      -0.400\n",
      "April              -1.9597      0.930     -2.107      0.035      -3.784      -0.135\n",
      "May                -0.7785      0.928     -0.839      0.402      -2.599       1.042\n",
      "June               -0.9207      0.929     -0.991      0.322      -2.743       0.902\n",
      "July               -2.3310      0.928     -2.512      0.012      -4.152      -0.510\n",
      "August             -0.5815      0.929     -0.626      0.531      -2.403       1.240\n",
      "September          -0.4218      0.929     -0.454      0.650      -2.243       1.400\n",
      "October            -0.6400      0.929     -0.689      0.491      -2.463       1.183\n",
      "November           -1.3974      0.928     -1.506      0.132      -3.217       0.422\n",
      "==============================================================================\n",
      "Omnibus:                      549.898   Durbin-Watson:                   1.751\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5137.347\n",
      "Skew:                           1.425   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.569   Cond. No.                     1.16e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.16e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "lsdv_model = smf.ols(formula=lsdv_expr, data=df_with_dummies)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "print(lsdv_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0178cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies.to_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\csv\\df_lag1_2016_n4.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c82327b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC = 10359.570121569952\n"
     ]
    }
   ],
   "source": [
    "#compute AIC\n",
    "print('AIC = ' + str(lsdv_model_results.aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a994ae6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sara/Documenti/GitHub/Climate-and-conflict/csv/dist_som.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\all codes\\Regression - 2020 - CRU4.07.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#dist = pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\dist_som.csv\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/home/sara/Documenti/GitHub/Climate-and-conflict/csv/dist_som.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sara/Documenti/GitHub/Climate-and-conflict/csv/dist_som.csv'"
     ]
    }
   ],
   "source": [
    "#dist = pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\dist_som.csv\")\n",
    "dist = pd.read_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/csv/dist_som.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dist = 1/(dist+0.001)\n",
    "inv_dist.reset_index(inplace=True)\n",
    "inv_dist['index'] = inv_dist['index'].replace(replacement_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5037a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new=df_with_dummies.merge(inv_dist, left_on='admin1', right_on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d5291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations to be tested: 125\n"
     ]
    }
   ],
   "source": [
    "lag_combinations = OrderedDict()\n",
    " \n",
    "for combination in itertools.product(range(1,6), repeat=3):\n",
    "        lag_combinations[combination] = 0.0\n",
    " \n",
    "print('Number of combinations to be tested: ' + str(len(lag_combinations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for expr: conflicts ~ TA_lag1 + PA_lag1 + DL_lag1 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n",
      "(1, 1, 1)\n",
      "AIC=10363.92100830666\n",
      "Building model for expr: conflicts ~ TA_lag1 + PA_lag1 + DL_lag2 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n",
      "(1, 1, 2)\n"
     ]
    },
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'DL_lag2' is not defined\n    conflicts ~ TA_lag1 + PA_lag1 + DL_lag2 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n                                    ^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\compat.py:36\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     37\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\eval.py:169\u001b[0m, in \u001b[0;36mEvalEnvironment.eval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    168\u001b[0m code \u001b[39m=\u001b[39m \u001b[39mcompile\u001b[39m(expr, source_name, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflags, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39meval\u001b[39m(code, {}, VarLookupDict([inner_namespace]\n\u001b[0;32m    170\u001b[0m                                     \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_namespaces))\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DL_lag2' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\all codes\\Regression - 2020 - CRU4.07.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X42sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(combination)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X42sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#Carve out the X,y vectors using patsy. We will use X_test, y_test later for testing the model.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X42sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m y_test, X_test \u001b[39m=\u001b[39m dmatrices(expr, df_with_dummies, return_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdataframe\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X42sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#Build and train the OLSR model on the training data set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PcLaptop/Documents/GitHub/Climate-and-conflict/all%20codes/Regression%20-%202020%20-%20CRU4.07.ipynb#X42sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m olsr_results \u001b[39m=\u001b[39m smf\u001b[39m.\u001b[39mols(expr, df_with_dummies)\u001b[39m.\u001b[39mfit()\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\highlevel.py:309\u001b[0m, in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[39mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m eval_env \u001b[39m=\u001b[39m EvalEnvironment\u001b[39m.\u001b[39mcapture(eval_env, reference\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 309\u001b[0m (lhs, rhs) \u001b[39m=\u001b[39m _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0;32m    310\u001b[0m                                   NA_action, return_type)\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m lhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m PatsyError(\u001b[39m\"\u001b[39m\u001b[39mmodel is missing required outcome variables\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_iter_maker\u001b[39m():\n\u001b[0;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m([data])\n\u001b[1;32m--> 164\u001b[0m design_infos \u001b[39m=\u001b[39m _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0;32m    165\u001b[0m                                   NA_action)\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m design_infos \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m build_design_matrices(design_infos, data,\n\u001b[0;32m    168\u001b[0m                                  NA_action\u001b[39m=\u001b[39mNA_action,\n\u001b[0;32m    169\u001b[0m                                  return_type\u001b[39m=\u001b[39mreturn_type)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\highlevel.py:66\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[0;32m     65\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m design_matrix_builders([formula_like\u001b[39m.\u001b[39;49mlhs_termlist,\n\u001b[0;32m     67\u001b[0m                                    formula_like\u001b[39m.\u001b[39;49mrhs_termlist],\n\u001b[0;32m     68\u001b[0m                                   data_iter_maker,\n\u001b[0;32m     69\u001b[0m                                   eval_env,\n\u001b[0;32m     70\u001b[0m                                   NA_action)\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\build.py:693\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    689\u001b[0m factor_states \u001b[39m=\u001b[39m _factors_memorize(all_factors, data_iter_maker, eval_env)\n\u001b[0;32m    690\u001b[0m \u001b[39m# Now all the factors have working eval methods, so we can evaluate them\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[39m# on some data to find out what type of data they return.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m (num_column_counts,\n\u001b[1;32m--> 693\u001b[0m  cat_levels_contrasts) \u001b[39m=\u001b[39m _examine_factor_types(all_factors,\n\u001b[0;32m    694\u001b[0m                                                factor_states,\n\u001b[0;32m    695\u001b[0m                                                data_iter_maker,\n\u001b[0;32m    696\u001b[0m                                                NA_action)\n\u001b[0;32m    697\u001b[0m \u001b[39m# Now we need the factor infos, which encapsulate the knowledge of\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39m# how to turn any given factor into a chunk of data:\u001b[39;00m\n\u001b[0;32m    699\u001b[0m factor_infos \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\build.py:443\u001b[0m, in \u001b[0;36m_examine_factor_types\u001b[1;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m data_iter_maker():\n\u001b[0;32m    442\u001b[0m     \u001b[39mfor\u001b[39;00m factor \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(examine_needed):\n\u001b[1;32m--> 443\u001b[0m         value \u001b[39m=\u001b[39m factor\u001b[39m.\u001b[39;49meval(factor_states[factor], data)\n\u001b[0;32m    444\u001b[0m         \u001b[39mif\u001b[39;00m factor \u001b[39min\u001b[39;00m cat_sniffers \u001b[39mor\u001b[39;00m guess_categorical(value):\n\u001b[0;32m    445\u001b[0m             \u001b[39mif\u001b[39;00m factor \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m cat_sniffers:\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\eval.py:568\u001b[0m, in \u001b[0;36mEvalFactor.eval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, memorize_state, data):\n\u001b[1;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval(memorize_state[\u001b[39m\"\u001b[39;49m\u001b[39meval_code\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    569\u001b[0m                       memorize_state,\n\u001b[0;32m    570\u001b[0m                       data)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\eval.py:551\u001b[0m, in \u001b[0;36mEvalFactor._eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_eval\u001b[39m(\u001b[39mself\u001b[39m, code, memorize_state, data):\n\u001b[0;32m    550\u001b[0m     inner_namespace \u001b[39m=\u001b[39m VarLookupDict([data, memorize_state[\u001b[39m\"\u001b[39m\u001b[39mtransforms\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[1;32m--> 551\u001b[0m     \u001b[39mreturn\u001b[39;00m call_and_wrap_exc(\u001b[39m\"\u001b[39;49m\u001b[39mError evaluating factor\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    552\u001b[0m                              \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    553\u001b[0m                              memorize_state[\u001b[39m\"\u001b[39;49m\u001b[39meval_env\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49meval,\n\u001b[0;32m    554\u001b[0m                              code,\n\u001b[0;32m    555\u001b[0m                              inner_namespace\u001b[39m=\u001b[39;49minner_namespace)\n",
      "File \u001b[1;32mc:\\Users\\PcLaptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\patsy\\compat.py:43\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     new_exc \u001b[39m=\u001b[39m PatsyError(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m                          \u001b[39m%\u001b[39m (msg, e\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, e),\n\u001b[0;32m     41\u001b[0m                          origin)\n\u001b[0;32m     42\u001b[0m     \u001b[39m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     exec(\u001b[39m\"\u001b[39m\u001b[39mraise new_exc from e\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[39m# In python 2, we just let the original exception escape -- better\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[39m# than destroying the traceback. But if it's a PatsyError, we can\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39m# at least set the origin properly.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, PatsyError):\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'DL_lag2' is not defined\n    conflicts ~ TA_lag1 + PA_lag1 + DL_lag2 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer + January + February + March + April + May + June + July + August + September + October + November\n                                    ^^^^^^^"
     ]
    }
   ],
   "source": [
    "X_var_ = ['TA_','PA_','DL_']\n",
    "expr_prefix = 'conflicts ~ '\n",
    " \n",
    "min_aic = sys.float_info.max\n",
    "best_expr = ''\n",
    "best_olsr_model_results = None\n",
    " \n",
    "#Iterate over each combination\n",
    "for combination in lag_combinations:\n",
    "    expr = expr_prefix\n",
    "    i = 1\n",
    "    #Setup the model expression using patsy syntax\n",
    "    for i, lag_num in enumerate(combination):\n",
    "        if i < len(combination)-1:\n",
    "            expr = expr  + X_var_[i] + 'lag' + str(lag_num) + ' + '\n",
    "        else:\n",
    "            expr = expr + X_var_[i] + 'lag' + str(lag_num)\n",
    " \n",
    "        i += 1\n",
    "    for dummy_name in unit_names[:-1]:\n",
    "        expr = expr + ' + ' + dummy_name\n",
    "    for dummy_name_t in unit_names_t[:-1]:\n",
    "        expr = expr + ' + ' + dummy_name_t\n",
    " \n",
    "    print('Building model for expr: ' + expr)\n",
    "    print(combination)\n",
    "\n",
    "    #Carve out the X,y vectors using patsy. We will use X_test, y_test later for testing the model.\n",
    "    y_test, X_test = dmatrices(expr, df_with_dummies, return_type='dataframe')\n",
    " \n",
    "    #Build and train the OLSR model on the training data set\n",
    "    olsr_results = smf.ols(expr, df_with_dummies).fit()\n",
    " \n",
    "    #Store it's AIC value\n",
    "    lag_combinations[combination] = olsr_results.aic\n",
    " \n",
    "    #Keep track of the best model (the one with the lowest AIC score) seen so far\n",
    "    if olsr_results.aic < min_aic:\n",
    "        min_aic = olsr_results.aic\n",
    "        best_expr = expr\n",
    "        best_olsr_model_results = olsr_results\n",
    " \n",
    "    print('AIC='+str(lag_combinations[combination]))\n",
    "\n",
    "print(best_olsr_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.445\n",
      "Model:                            OLS   Adj. R-squared:                  0.442\n",
      "Method:                 Least Squares   F-statistic:                     144.2\n",
      "Date:                Wed, 04 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        10:47:33   Log-Likelihood:                -20960.\n",
      "No. Observations:                5616   AIC:                         4.198e+04\n",
      "Df Residuals:                    5584   BIC:                         4.220e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          -0.9813      0.750     -1.309      0.191      -2.451       0.488\n",
      "TA_lag2             2.4191      0.239     10.135      0.000       1.951       2.887\n",
      "PA_lag4             1.8208      0.418      4.352      0.000       1.001       2.641\n",
      "DL_lag5             0.0814      0.005     15.528      0.000       0.071       0.092\n",
      "Awdal              -7.9351      0.914     -8.683      0.000      -9.727      -6.144\n",
      "Bakool              2.3877      0.815      2.930      0.003       0.790       3.985\n",
      "Banadir            35.7050      0.818     43.648      0.000      34.101      37.309\n",
      "Bari                3.1664      0.813      3.896      0.000       1.573       4.760\n",
      "Bay                 7.1178      0.816      8.720      0.000       5.518       8.718\n",
      "Galgaduud           4.5912      0.823      5.576      0.000       2.977       6.205\n",
      "Gedo                2.7364      0.819      3.342      0.001       1.131       4.341\n",
      "Hiraan              8.2566      0.820     10.072      0.000       6.650       9.864\n",
      "Lower_Juba          7.2914      0.818      8.912      0.000       5.688       8.895\n",
      "Lower_Shabelle     20.1236      0.815     24.692      0.000      18.526      21.721\n",
      "Middle_Juba        -2.0084      0.817     -2.457      0.014      -3.611      -0.406\n",
      "Middle_Shabelle     7.0502      0.825      8.543      0.000       5.432       8.668\n",
      "Mudug               5.1423      0.824      6.243      0.000       3.527       6.757\n",
      "Nugaal              1.1636      0.819      1.420      0.156      -0.443       2.770\n",
      "Sanaag              0.2652      0.812      0.327      0.744      -1.327       1.857\n",
      "Sool                1.3925      0.814      1.711      0.087      -0.203       2.988\n",
      "Togdheer            0.6041      0.812      0.744      0.457      -0.988       2.196\n",
      "January            -0.4173      0.663     -0.629      0.529      -1.717       0.883\n",
      "February           -0.4153      0.664     -0.626      0.532      -1.716       0.886\n",
      "March              -0.4944      0.663     -0.746      0.456      -1.794       0.805\n",
      "April              -1.0281      0.663     -1.551      0.121      -2.328       0.272\n",
      "May                -0.3696      0.663     -0.558      0.577      -1.669       0.930\n",
      "June               -0.0437      0.663     -0.066      0.947      -1.343       1.256\n",
      "July                0.0536      0.663      0.081      0.936      -1.246       1.353\n",
      "August              0.0369      0.663      0.056      0.956      -1.262       1.336\n",
      "September          -0.6330      0.663     -0.955      0.340      -1.932       0.666\n",
      "October            -0.3560      0.663     -0.537      0.591      -1.656       0.944\n",
      "November           -0.5920      0.663     -0.893      0.372      -1.892       0.708\n",
      "==============================================================================\n",
      "Omnibus:                     1896.165   Durbin-Watson:                   1.517\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22024.323\n",
      "Skew:                           1.276   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.360   Cond. No.                         730.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(best_olsr_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74eb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32aca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
