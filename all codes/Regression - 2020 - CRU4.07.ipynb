{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "49af736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "from datetime import datetime\n",
    "#import scipy\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ebf15",
   "metadata": {},
   "source": [
    "Data from UEA CRU TS4.07 (1901-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fd212166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\cru_ts4.07.1901.2022.tmx.dat.nc\"\n",
    "# file2 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\cru_ts4.07.1901.2022.pre.dat.nc\"\n",
    "\n",
    "# file_paths_list =[file,file2]\n",
    "# monthly_forecast=xr.Dataset()\n",
    "\n",
    "# for file in file_paths_list:\n",
    "#         monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2646f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/cru_ts4.07.1901.2022.pre.dat.nc\"\n",
    "file2 = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/cru_ts4.07.1901.2022.tmx.dat.nc\"\n",
    "\n",
    "file_paths_list =[file,file2]\n",
    "monthly_forecast=xr.Dataset()\n",
    "\n",
    "for file in file_paths_list:\n",
    "        monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='override')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53f58",
   "metadata": {},
   "source": [
    "Data on conflict events from ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "45e1de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "# df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ffb3bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f32fa7",
   "metadata": {},
   "source": [
    "Shapefile with administrative boundaries of Somalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "140d777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "# states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "25cb8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/home/sara/Documenti/GitHub/Climate-and-conflict/Datasets/som_adm_ocha_itos_20230308_shp/som_admbnda_adm1_ocha_20230308.shp\"\n",
    "states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a83aa8",
   "metadata": {},
   "source": [
    "Limit the lat-lon and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e4ad81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(shp, world=True):\n",
    "    lon_lat = {}\n",
    "    # Get lat min, max\n",
    "    aoi_lat = [float(shp.total_bounds[1]), float(shp.total_bounds[3])]\n",
    "    aoi_lon = [float(shp.total_bounds[0]), float(shp.total_bounds[2])]\n",
    "\n",
    "    lon_lat[\"lon\"] = aoi_lon\n",
    "    lon_lat[\"lat\"] = aoi_lat\n",
    "    return lon_lat\n",
    "\n",
    "bounds = get_aoi(states_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e765a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1901-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "region = monthly_forecast[[\"pre\",'tmx']].sel(\n",
    "    time=slice(start_date, end_date),\n",
    "    lon=slice(bounds[\"lon\"][0], bounds[\"lon\"][1]),\n",
    "    lat=slice(bounds[\"lat\"][0], bounds[\"lat\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1382c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = regionmask.mask_3D_geopandas(states_gdf,\n",
    "                                         monthly_forecast.lon,\n",
    "                                         monthly_forecast.lat)\n",
    "\n",
    "temp_pre = region.where(region_mask)\n",
    "\n",
    "temp_pre = temp_pre.groupby(\"time\").mean([\"lat\", \"lon\"]).to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "74921595",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {0  :  'Awdal',\n",
    "1    :         'Bakool',\n",
    "2      :       'Banadir',\n",
    "3      :         'Bari',\n",
    "4       :         'Bay',\n",
    "5        :  'Galgaduud',\n",
    "6          :      'Gedo',\n",
    "7          :   'Hiraan',\n",
    "8   :       'Lower_Juba',\n",
    "9   :   'Lower_Shabelle',\n",
    "10  :      'Middle_Juba',\n",
    "11   : 'Middle_Shabelle',\n",
    "12    :          'Mudug',\n",
    "13    :        'Nugaal',\n",
    "14      :       'Sanaag',\n",
    "15       :        'Sool',\n",
    "16        :   'Togdheer',\n",
    "17   : 'Woqooyi_Galbeed'}\n",
    "\n",
    "temp_pre['admin1'] = temp_pre['region'].replace(replacement_dict)\n",
    "df['admin1'] = df['admin1'].str.replace(' ', '_')\n",
    "temp_pre.drop('region', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f50e3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify event_date column to datetime\n",
    "\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df = df.set_index('event_date') \n",
    "\n",
    "conflict = df.groupby([pd.Grouper(freq='M'),\"admin1\"]).count()\n",
    "conflict.reset_index(level=[0, 1], inplace=True)\n",
    "conflict = conflict[['event_date','admin1','year']].rename(columns={'year': 'conflicts','event_date': 'time'})\n",
    "\n",
    "# Aggregate the datetime objects by month\n",
    "conf = conflict.groupby([pd.Grouper(key='time', freq='M'),'admin1'])['conflicts'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ee086f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame with all dates and districts and fill missing values with 0\n",
    "\n",
    "dates = conf.index.get_level_values('time').unique()\n",
    "districts = conf.index.get_level_values('admin1').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts], names=['time', 'admin1'])\n",
    "\n",
    "conflicts = conf.reindex(all_combinations, fill_value=0).reset_index()    \n",
    "conflicts = conflicts.sort_values(by=['time', 'admin1'], ascending=[True, True])\n",
    "conflicts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f8b312de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Banadir region with tmx and pre as mean of the neighbouring regions\n",
    "\n",
    "district1 = 'Lower_Shabelle'  \n",
    "district2 = 'Middle_Shabelle'  \n",
    "\n",
    "# Calculate the mean tmx and pre for the neighboring districts\n",
    "mean_t = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['tmx'].mean()\n",
    "mean_p = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['pre'].mean()\n",
    "\n",
    "new_data = pd.DataFrame({ 'admin1': 'Banadir', 'tmx': mean_t, 'pre': mean_p}).reset_index()\n",
    "\n",
    "# Append the new DataFrame to the original DataFrame\n",
    "df3 = pd.concat([temp_pre, new_data])\n",
    "\n",
    "temp_pre = df3.sort_values(by=['time', 'admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7dbb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep month and year in time column in temp_pre and conflicts\n",
    "\n",
    "temp_pre['time'] = pd.to_datetime(temp_pre['time']).dt.strftime('%Y-%m-%d')\n",
    "temp_pre['month'] = temp_pre['time'].str[5:7]\n",
    "temp_pre['month_year'] = temp_pre['time'].str[:7]\n",
    "conflicts['time'] = conflicts['time'].dt.strftime('%Y-%m').values\n",
    "\n",
    "temp_pre = temp_pre[['month_year','admin1','tmx','pre']]\n",
    "temp_pre = temp_pre.rename(columns={'month_year':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e4a05554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into regions\n",
    "\n",
    "reg=[]\n",
    "for admin in temp_pre['admin1'].unique():\n",
    "    a = temp_pre[temp_pre['admin1']==admin].reset_index(drop=True)\n",
    "    reg.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "80cdd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TA (temperature anomaly), PA (precipitation anomaly) and DL (drought lenght) for each region\n",
    "\n",
    "avg_t = avg_p = std_t = std_p = np.zeros(18)\n",
    "\n",
    "for i in range(18):\n",
    "\n",
    "    reg[i]['year'] , reg[i]['month'] = reg[i]['time'].str[:4] , reg[i]['time'].str[5:7]\n",
    "\n",
    "    # TA\n",
    "    mean_temp_i , std_temp_i  = reg[i].groupby('month')['tmx'].mean() , reg[i].groupby('month')['tmx'].std()\n",
    "    reg[i]['avg_temp'] , reg[i]['std_temp']  = reg[i]['month'].map(mean_temp_i) , reg[i]['month'].map(std_temp_i)\n",
    "    reg[i]['diff_t']= (reg[i]['tmx']-reg[i]['avg_temp'])/reg[i]['std_temp']\n",
    "    reg[i]['TA'] = (reg[i]['diff_t'].shift(2) + reg[i]['diff_t'].shift(1) + reg[i]['diff_t'])/3\n",
    "\n",
    "    # PA\n",
    "    mean_pre_i , std_pre_i  = reg[i].groupby('month')['pre'].mean() , reg[i].groupby('month')['pre'].std()\n",
    "    reg[i]['avg_pre'] , reg[i]['std_pre']= reg[i]['month'].map(mean_pre_i) , reg[i]['month'].map(std_pre_i)\n",
    "    reg[i]['diff_p']= (reg[i]['pre']-reg[i]['avg_pre'])/reg[i]['std_pre']\n",
    "    reg[i]['PA'] = (reg[i]['diff_p'].shift(2) + reg[i]['diff_p'].shift(1) + reg[i]['diff_p'])/3\n",
    "    \n",
    "    # DL \n",
    "    reg[i]['DL'] = 0\n",
    "    mask = reg[i]['TA'] > 0\n",
    "    group_id = (mask != mask.shift()).cumsum()             # Create a group identifier for each consecutive group\n",
    "    count = reg[i].groupby(group_id).cumcount() + 1        # Calculate the count within each group\n",
    "    reg[i]['DL'] = np.where(mask, count, 0)                # Assign the count values to the 'DL' column\n",
    "\n",
    "    # add columns TA_lag1, TA_lag2, TA_lag3, TA_lag4, PA_lag1, PA_lag2, DL_lag1, DL_lag2, DL_lag3, DL_lag4, DL_lag5\n",
    "    reg[i]['TA_lag1'] = reg[i]['TA'].shift(1)\n",
    "    reg[i]['TA_lag2'] = reg[i]['TA'].shift(2)\n",
    "    reg[i]['TA_lag3'] = reg[i]['TA'].shift(3)\n",
    "    reg[i]['TA_lag4'] = reg[i]['TA'].shift(4)\n",
    "    reg[i]['TA_lag5'] = reg[i]['TA'].shift(5)\n",
    "\n",
    "    reg[i]['PA_lag1'] = reg[i]['PA'].shift(1)\n",
    "    reg[i]['PA_lag2'] = reg[i]['PA'].shift(2)\n",
    "    reg[i]['PA_lag3'] = reg[i]['PA'].shift(3)\n",
    "    reg[i]['PA_lag4'] = reg[i]['PA'].shift(4)\n",
    "    reg[i]['PA_lag5'] = reg[i]['PA'].shift(5)\n",
    "\n",
    "    reg[i]['DL_lag1'] = reg[i]['DL'].shift(1)\n",
    "    reg[i]['DL_lag2'] = reg[i]['DL'].shift(2)\n",
    "    reg[i]['DL_lag3'] = reg[i]['DL'].shift(3)\n",
    "    reg[i]['DL_lag4'] = reg[i]['DL'].shift(4)\n",
    "    reg[i]['DL_lag5'] = reg[i]['DL'].shift(5)\n",
    "\n",
    "\n",
    "    reg[i] = reg[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3dd81ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre_c = pd.concat([reg[i] for i in range(18)], axis=0)\n",
    "temp_pre_c = temp_pre_c.dropna()\n",
    "\n",
    "# Select a subset of the dataframes from 1997-01 to 2009-12\n",
    "\n",
    "start='2005-01'\n",
    "end='2022-12'\n",
    "temp_pre_97_09 = temp_pre_c[(temp_pre_c['time'] >= start) & (temp_pre_c['time'] <= end)]\n",
    "conflicts_97_09 = conflicts[(conflicts['time'] >= start) & (conflicts['time'] <= end)]\n",
    "\n",
    "df_c_97_09 = pd.merge(temp_pre_97_09, conflicts_97_09, on=['time','admin1'], how='outer')\n",
    "df_c_97_09 = df_c_97_09.fillna(0)\n",
    "df_c_97_09 = df_c_97_09.drop(['avg_temp', 'avg_pre', 'std_temp', 'std_pre', 'diff_t', 'diff_p', 'tmx', 'pre'], axis=1)\n",
    "df_c_97_09 = df_c_97_09.sort_values(by=['time','admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a1d7743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummy variables\n",
    "\n",
    "#one for each country\n",
    "df_dummies = pd.get_dummies(df_c_97_09['admin1'])\n",
    "df_with_dummies = df_c_97_09.join(df_dummies)\n",
    "\n",
    "#one for each month\n",
    "df_c_97_09['month'] = pd.DatetimeIndex(df_c_97_09['time']).month_name()\n",
    "df_dummies_m = pd.get_dummies(df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_m)\n",
    "df_with_dummies['month'] = pd.DatetimeIndex(df_c_97_09['time']).month\n",
    "\n",
    "#one for each for each country-month pair\n",
    "df_dummies_mr = pd.get_dummies(df_c_97_09['admin1'] + df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_mr)\n",
    "df_with_dummies = df_with_dummies.replace({True: 1, False: 0})\n",
    "\n",
    "#create a dictionary where the keys are increasing integers and the values are the values of the time column\n",
    "time_dict = dict(enumerate(df_c_97_09['time'].unique(), 25))\n",
    "inv_time_dict = {v: k for k, v in time_dict.items()}\n",
    "\n",
    "#create a new variable for the month_year column\n",
    "df_c_97_09['time'].replace(inv_time_dict, inplace=True)\n",
    "\n",
    "df_dummies_new = pd.get_dummies(df_c_97_09['time'], drop_first=True)\n",
    "df_dummies_new = df_dummies_new.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a308b3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_with_dummies['year'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d0888b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_name = 'conflicts'\n",
    "X_var_names = ['TA_lag4','PA_lag4','DL_lag4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a893f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression expression for OLS with dummies=conflicts ~ TA_lag4 + PA_lag4 + DL_lag4 + Awdal + Bakool + Banadir + Bari + Bay + Galgaduud + Gedo + Hiraan + Lower_Juba + Lower_Shabelle + Middle_Juba + Middle_Shabelle + Mudug + Nugaal + Sanaag + Sool + Togdheer\n"
     ]
    }
   ],
   "source": [
    "# Regression expression for OLS with dummies\n",
    "\n",
    "unit_names = df_c_97_09['admin1'].unique().tolist()\n",
    "unit_names.sort()\n",
    "unit_names_t = df_c_97_09['month'].unique().tolist()\n",
    "unit_names_my = df_c_97_09['time'].astype(str).unique().tolist()\n",
    "unit_names_mr = (df_c_97_09['admin1'] + df_c_97_09['month']).unique().tolist()\n",
    "unit_names_myr = (df_c_97_09['admin1'] + df_c_97_09['time'].astype(str)).unique().tolist()\n",
    "\n",
    "lsdv_expr = y_var_name + ' ~ '\n",
    "i = 0\n",
    "for X_var_name in X_var_names:\n",
    "    if i > 0:\n",
    "        lsdv_expr = lsdv_expr + ' + ' + X_var_name\n",
    "    else:\n",
    "        lsdv_expr = lsdv_expr + X_var_name\n",
    "    i = i + 1\n",
    "for dummy_name in unit_names[:-1]:\n",
    "   lsdv_expr = lsdv_expr + ' + ' + dummy_name\n",
    "#for dummy_name_t in unit_names_t[:-1]:\n",
    "    #lsdv_expr = lsdv_expr + ' + ' + dummy_name_t\n",
    "#for dummy_name_mr in unit_names_mr[:-1]:\n",
    "    #lsdv_expr = lsdv_expr + ' + ' + dummy_name_mr\n",
    "#lsdv_expr = lsdv_expr + ' - ' + '1'\n",
    "print('Regression expression for OLS with dummies=' + lsdv_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9af6641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.615\n",
      "Model:                            OLS   Adj. R-squared:                  0.613\n",
      "Method:                 Least Squares   F-statistic:                     308.5\n",
      "Date:                Fri, 15 Sep 2023   Prob (F-statistic):               0.00\n",
      "Time:                        18:04:37   Log-Likelihood:                -14275.\n",
      "No. Observations:                3888   AIC:                         2.859e+04\n",
      "Df Residuals:                    3867   BIC:                         2.872e+04\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           0.0487      0.689      0.071      0.944      -1.301       1.399\n",
      "TA_lag4             1.5279      0.274      5.582      0.000       0.991       2.065\n",
      "PA_lag4             0.8810      0.562      1.569      0.117      -0.220       1.982\n",
      "DL_lag4             0.0657      0.006     10.832      0.000       0.054       0.078\n",
      "Awdal              -8.9852      1.136     -7.910      0.000     -11.212      -6.758\n",
      "Bakool              2.7136      0.922      2.943      0.003       0.906       4.521\n",
      "Banadir            47.6880      0.926     51.507      0.000      45.873      49.503\n",
      "Bari                4.6375      0.920      5.040      0.000       2.834       6.442\n",
      "Bay                 9.5945      0.927     10.351      0.000       7.777      11.412\n",
      "Galgaduud           5.1223      0.933      5.488      0.000       3.292       6.952\n",
      "Gedo                4.1748      0.931      4.485      0.000       2.350       6.000\n",
      "Hiraan             10.3859      0.928     11.192      0.000       8.567      12.205\n",
      "Lower_Juba         11.2867      0.929     12.150      0.000       9.465      13.108\n",
      "Lower_Shabelle     28.3563      0.924     30.690      0.000      26.545      30.168\n",
      "Middle_Juba        -2.3421      0.930     -2.518      0.012      -4.165      -0.519\n",
      "Middle_Shabelle     8.5353      0.935      9.128      0.000       6.702      10.369\n",
      "Mudug               6.0066      0.934      6.430      0.000       4.175       7.838\n",
      "Nugaal              0.6784      0.929      0.730      0.465      -1.143       2.499\n",
      "Sanaag              0.0943      0.919      0.103      0.918      -1.707       1.896\n",
      "Sool                1.3517      0.921      1.468      0.142      -0.453       3.157\n",
      "Togdheer            0.4542      0.919      0.494      0.621      -1.347       2.255\n",
      "==============================================================================\n",
      "Omnibus:                      967.120   Durbin-Watson:                   1.548\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13603.001\n",
      "Skew:                           0.790   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.026   Cond. No.                         866.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lsdv_model = smf.ols(formula=lsdv_expr, data=df_with_dummies)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "print(lsdv_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0178cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies.to_csv(r'/home/sara/Documenti/GitHub/Climate-and-conflict/df_CRU4.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c82327b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC = 28636.08523871169\n"
     ]
    }
   ],
   "source": [
    "#compute AIC\n",
    "print('AIC = ' + str(lsdv_model_results.aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a994ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\dist_som.csv\")\n",
    "dist = pd.read_csv(r\"/home/sara/Documenti/GitHub/Climate-and-conflict/dist_som.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "78de8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dist = 1/(dist+0.001)\n",
    "inv_dist.reset_index(inplace=True)\n",
    "inv_dist['index'] = inv_dist['index'].replace(replacement_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a5037a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new=df_with_dummies.merge(inv_dist, left_on='admin1', right_on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880adfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
