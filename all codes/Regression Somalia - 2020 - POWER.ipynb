{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49af736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/.local/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_42749/1413625899.py:8: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ebf15",
   "metadata": {},
   "source": [
    "Data from POWER Data Access Viewer - NASA (1997-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd212166",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "no files to open",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/sara/Documenti/GitHub/Climate-and-conflict/all codes/Regression Somalia - 2020 - POWER.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20Somalia%20-%202020%20-%20POWER.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m monthly_forecast\u001b[39m=\u001b[39mxr\u001b[39m.\u001b[39mDataset()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20Somalia%20-%202020%20-%20POWER.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m file_paths_list:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sara/Documenti/GitHub/Climate-and-conflict/all%20codes/Regression%20Somalia%20-%202020%20-%20POWER.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         monthly_forecast \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mmerge([monthly_forecast,xr\u001b[39m.\u001b[39;49mopen_mfdataset(file)], compat\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mno_conflicts\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xarray/backends/api.py:963\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m     paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mfspath(p) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(p, os\u001b[39m.\u001b[39mPathLike) \u001b[39melse\u001b[39;00m p \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m paths]\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m paths:\n\u001b[0;32m--> 963\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno files to open\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    965\u001b[0m \u001b[39mif\u001b[39;00m combine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnested\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    966\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(concat_dim, (\u001b[39mstr\u001b[39m, DataArray)) \u001b[39mor\u001b[39;00m concat_dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: no files to open"
     ]
    }
   ],
   "source": [
    "da1 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\POWER_Regional_monthly_1997_2020.nc\"\n",
    "da2 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\POWER_Regional_monthly_1997_2020_south.nc\"\n",
    "\n",
    "file_paths_list =[da1,da2]\n",
    "monthly_forecast=xr.Dataset()\n",
    "\n",
    "for file in file_paths_list:\n",
    "        monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='no_conflicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35124662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'T2M_MAX':'tmx' in monthly_forecast\n",
    "monthly_forecast = monthly_forecast.rename({'T2M_MAX':'tmx','PRECTOTCORR':'pre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b87061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the extra month\n",
    "monthly_forecast = monthly_forecast.sel(time=~((monthly_forecast.time.astype(str).str[4:6] == '13') ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53f58",
   "metadata": {},
   "source": [
    "Data on conflict events from ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "#remove events types of strategic developments\n",
    "df = df[df['event_type'] != 'Strategic developments']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f32fa7",
   "metadata": {},
   "source": [
    "Shapefile with administrative boundaries of Somalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a83aa8",
   "metadata": {},
   "source": [
    "Limit the lat-lon and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(shp, world=True):\n",
    "    lon_lat = {}\n",
    "    # Get lat min, max\n",
    "    aoi_lat = [float(shp.total_bounds[1]), float(shp.total_bounds[3])]\n",
    "    aoi_lon = [float(shp.total_bounds[0]), float(shp.total_bounds[2])]\n",
    "\n",
    "    lon_lat[\"lon\"] = aoi_lon\n",
    "    lon_lat[\"lat\"] = aoi_lat\n",
    "    return lon_lat\n",
    "\n",
    "bounds = get_aoi(states_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1980-01-01'\n",
    "end_date = '2020-12-31'\n",
    "\n",
    "region = monthly_forecast[[\"pre\",'tmx']].sel(\n",
    "    time=slice(start_date, end_date),\n",
    "    lon=slice(bounds[\"lon\"][0], bounds[\"lon\"][1]),\n",
    "    lat=slice(bounds[\"lat\"][0], bounds[\"lat\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = regionmask.mask_3D_geopandas(states_gdf,\n",
    "                                         monthly_forecast.lon,\n",
    "                                         monthly_forecast.lat)\n",
    "\n",
    "temp_pre = region.where(region_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre['time']=temp_pre['time'].astype(str)\n",
    "temp_pre = temp_pre.groupby(\"time\").mean([\"lat\", \"lon\"]).to_dataframe().reset_index()\n",
    "temp_pre['time'] = temp_pre['time'].str[:4] + '-' + temp_pre['time'].str[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74921595",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {0  :  'Awdal',\n",
    "1    :         'Bakool',\n",
    "2      :       'Banadir',\n",
    "3      :         'Bari',\n",
    "4       :         'Bay',\n",
    "5        :  'Galgaduud',\n",
    "6          :      'Gedo',\n",
    "7          :   'Hiraan',\n",
    "8   :       'Lower_Juba',\n",
    "9   :   'Lower_Shabelle',\n",
    "10  :      'Middle_Juba',\n",
    "11   : 'Middle_Shabelle',\n",
    "12    :          'Mudug',\n",
    "13    :        'Nugaal',\n",
    "14      :       'Sanaag',\n",
    "15       :        'Sool',\n",
    "16        :   'Togdheer',\n",
    "17   : 'Woqooyi_Galbeed'}\n",
    "\n",
    "temp_pre['admin1'] = temp_pre['region'].replace(replacement_dict)\n",
    "df['admin1'] = df['admin1'].str.replace(' ', '_')\n",
    "temp_pre.drop('region', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify event_date column to datetime\n",
    "\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df = df.set_index('event_date') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = df.groupby([pd.Grouper(freq='M'),\"admin1\"]).count()\n",
    "conflict.reset_index(level=[0, 1], inplace=True)\n",
    "conflict = conflict[['event_date','admin1','year']].rename(columns={'year': 'conflicts','event_date': 'time'})\n",
    "\n",
    "# Aggregate the datetime objects by month\n",
    "conf = conflict.groupby([pd.Grouper(key='time', freq='M'),'admin1'])['conflicts'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee086f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame with all dates and districts and fill missing values with 0\n",
    "\n",
    "dates = conf.index.get_level_values('time').unique()\n",
    "districts = conf.index.get_level_values('admin1').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts], names=['time', 'admin1'])\n",
    "\n",
    "conflicts = conf.reindex(all_combinations, fill_value=0).reset_index()    \n",
    "conflicts = conflicts.sort_values(by=['time', 'admin1'], ascending=[True, True])\n",
    "conflicts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b312de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Banadir region with tmx and pre as mean of the neighbouring regions\n",
    "\n",
    "district1 = 'Lower_Shabelle'  \n",
    "district2 = 'Middle_Shabelle'  \n",
    "\n",
    "# Calculate the mean tmx and pre for the neighboring districts\n",
    "mean_t = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['tmx'].mean()\n",
    "mean_p = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['pre'].mean()\n",
    "\n",
    "new_data = pd.DataFrame({ 'admin1': 'Banadir', 'tmx': mean_t, 'pre': mean_p}).reset_index()\n",
    "\n",
    "# Append the new DataFrame to the original DataFrame\n",
    "df3 = pd.concat([temp_pre, new_data])\n",
    "temp_pre = df3.sort_values(by=['time', 'admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre['month'] = temp_pre['time'].str[5:7]\n",
    "conflicts['time'] = conflicts['time'].dt.strftime('%Y-%m').values\n",
    "temp_pre = temp_pre[['time','admin1','tmx','pre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a05554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into regions\n",
    "\n",
    "reg=[]\n",
    "for admin in temp_pre['admin1'].unique():\n",
    "    a = temp_pre[temp_pre['admin1']==admin].reset_index(drop=True)\n",
    "    reg.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TA (temperature anomaly), PA (precipitation anomaly) and DL (drought lenght) for each region\n",
    "\n",
    "avg_t = avg_p = std_t = std_p = np.zeros(18)\n",
    "\n",
    "for i in range(18):\n",
    "\n",
    "    reg[i]['year'] , reg[i]['month'] = reg[i]['time'].str[:4] , reg[i]['time'].str[5:7]\n",
    "\n",
    "    # TA\n",
    "    mean_temp_i , std_temp_i  = reg[i].groupby('month')['tmx'].mean() , reg[i].groupby('month')['tmx'].std()\n",
    "    reg[i]['avg_temp'] , reg[i]['std_temp']  = reg[i]['month'].map(mean_temp_i) , reg[i]['month'].map(std_temp_i)\n",
    "    reg[i]['diff_t']= (reg[i]['tmx']-reg[i]['avg_temp'])/reg[i]['std_temp']\n",
    "    reg[i]['TA'] = (reg[i]['diff_t'].shift(2) + reg[i]['diff_t'].shift(1) + reg[i]['diff_t'])/3\n",
    "\n",
    "    # PA\n",
    "    mean_pre_i , std_pre_i  = reg[i].groupby('month')['pre'].mean() , reg[i].groupby('month')['pre'].std()\n",
    "    reg[i]['avg_pre'] , reg[i]['std_pre']= reg[i]['month'].map(mean_pre_i) , reg[i]['month'].map(std_pre_i)\n",
    "    reg[i]['diff_p']= (reg[i]['pre']-reg[i]['avg_pre'])/reg[i]['std_pre']\n",
    "    reg[i]['PA'] = (reg[i]['diff_p'].shift(2) + reg[i]['diff_p'].shift(1) + reg[i]['diff_p'])/3\n",
    "    \n",
    "    # DL \n",
    "    reg[i]['DL'] = 0\n",
    "    mask = reg[i]['TA'] > 0\n",
    "    group_id = (mask != mask.shift()).cumsum()             # Create a group identifier for each consecutive group\n",
    "    count = reg[i].groupby(group_id).cumcount() + 1        # Calculate the count within each group\n",
    "    reg[i]['DL'] = np.where(mask, count, 0)                # Assign the count values to the 'DL' column\n",
    "\n",
    "    # add columns TA_lag1, TA_lag2, TA_lag3, TA_lag4, PA_lag1, PA_lag2, DL_lag1, DL_lag2, DL_lag3, DL_lag4, DL_lag5\n",
    "    # reg[i]['TA_lag1'] = reg[i]['TA'].shift(1)\n",
    "    # reg[i]['TA_lag2'] = reg[i]['TA'].shift(2)\n",
    "    # reg[i]['TA_lag3'] = reg[i]['TA'].shift(3)\n",
    "    # reg[i]['TA_lag4'] = reg[i]['TA'].shift(4)\n",
    "    # reg[i]['TA_lag5'] = reg[i]['TA'].shift(5)\n",
    "\n",
    "    # reg[i]['PA_lag1'] = reg[i]['PA'].shift(1)\n",
    "    # reg[i]['PA_lag2'] = reg[i]['PA'].shift(2)\n",
    "    # reg[i]['PA_lag3'] = reg[i]['PA'].shift(3)\n",
    "    # reg[i]['PA_lag4'] = reg[i]['PA'].shift(4)\n",
    "    # reg[i]['PA_lag5'] = reg[i]['PA'].shift(5)\n",
    "\n",
    "    # reg[i]['DL_lag1'] = reg[i]['DL'].shift(1)\n",
    "    # reg[i]['DL_lag2'] = reg[i]['DL'].shift(2)\n",
    "    # reg[i]['DL_lag3'] = reg[i]['DL'].shift(3)\n",
    "    # reg[i]['DL_lag4'] = reg[i]['DL'].shift(4)\n",
    "    # reg[i]['DL_lag5'] = reg[i]['DL'].shift(5)\n",
    "\n",
    "    reg[i] = reg[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd81ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre_c = pd.concat([reg[i] for i in range(18)], axis=0)\n",
    "temp_pre_c = temp_pre_c.dropna()\n",
    "# Select a subset of the dataframes from 1997-01 to 2009-12\n",
    "\n",
    "start='1997-01'\n",
    "end='2009-12'\n",
    "temp_pre_97_09 = temp_pre_c[(temp_pre_c['time'] >= start) & (temp_pre_c['time'] <= end)]\n",
    "conflicts_97_09 = conflicts[(conflicts['time'] >= start) & (conflicts['time'] <= end)]\n",
    "\n",
    "df_c_97_09 = pd.merge(temp_pre_97_09, conflicts_97_09, on=['time','admin1'], how='outer')\n",
    "df_c_97_09 = df_c_97_09.fillna(0)\n",
    "df_c_97_09 = df_c_97_09.drop(['avg_temp', 'avg_pre', 'std_temp', 'std_pre', 'diff_t', 'diff_p', 'tmx', 'pre'], axis=1)\n",
    "df_c_97_09 = df_c_97_09.sort_values(by=['time','admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummy variables\n",
    "\n",
    "#one for each country\n",
    "df_dummies = pd.get_dummies(df_c_97_09['admin1'])\n",
    "df_with_dummies = df_c_97_09.join(df_dummies)\n",
    "\n",
    "#one for each month\n",
    "df_c_97_09['month'] = pd.DatetimeIndex(df_c_97_09['time']).month_name()\n",
    "df_dummies_m = pd.get_dummies(df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_m)\n",
    "df_with_dummies['month'] = pd.DatetimeIndex(df_c_97_09['time']).month\n",
    "\n",
    "#one for each for each country-month pair\n",
    "df_dummies_mr = pd.get_dummies(df_c_97_09['admin1'] + df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_mr)\n",
    "df_with_dummies = df_with_dummies.replace({True: 1, False: 0})\n",
    "\n",
    "#create a dictionary where the keys are increasing integers and the values are the values of the time column\n",
    "time_dict = dict(enumerate(df_c_97_09['time'].unique(), 25))\n",
    "inv_time_dict = {v: k for k, v in time_dict.items()}\n",
    "\n",
    "#create a new variable for the month_year column\n",
    "df_c_97_09['time'].replace(inv_time_dict, inplace=True)\n",
    "\n",
    "df_dummies_new = pd.get_dummies(df_c_97_09['time'].astype(str), drop_first=True)\n",
    "df_dummies_new = df_dummies_new.replace({True: 1, False: 0})\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0888b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_name = 'conflicts'\n",
    "X_var_names = ['TA','PA','DL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression expression for OLS with dummies=conflicts ~ TA + PA + DL + AwdalJanuary + BakoolJanuary + BanadirJanuary + BariJanuary + BayJanuary + GalgaduudJanuary + GedoJanuary + HiraanJanuary + Lower_JubaJanuary + Lower_ShabelleJanuary + Middle_JubaJanuary + Middle_ShabelleJanuary + MudugJanuary + NugaalJanuary + SanaagJanuary + SoolJanuary + TogdheerJanuary\n"
     ]
    }
   ],
   "source": [
    "# Regression expression for OLS with dummies\n",
    "\n",
    "unit_names = df_c_97_09['admin1'].unique().tolist()\n",
    "unit_names.sort()\n",
    "unit_names_t = df_c_97_09['month'].unique().tolist()\n",
    "unit_names_my = df_c_97_09['time'].astype(str).unique().tolist()\n",
    "unit_names_mr = (df_c_97_09['admin1'] + df_c_97_09['month']).unique().tolist()\n",
    "unit_names_myr = (df_c_97_09['admin1'] + df_c_97_09['time'].astype(str)).unique().tolist()\n",
    "\n",
    "lsdv_expr = y_var_name + ' ~ '\n",
    "i = 0\n",
    "for X_var_name in X_var_names:\n",
    "    if i > 0:\n",
    "        lsdv_expr = lsdv_expr + ' + ' + X_var_name\n",
    "    else:\n",
    "        lsdv_expr = lsdv_expr + X_var_name\n",
    "    i = i + 1\n",
    "#for dummy_name in unit_names[:-1]:\n",
    "  # lsdv_expr = lsdv_expr + ' + ' + dummy_name\n",
    "#or dummy_name_t in unit_names_t[:-1]:\n",
    "   #lsdv_expr = lsdv_expr + ' + ' + dummy_name_t\n",
    "for dummy_name_mr in unit_names_mr[:-1]:\n",
    "    lsdv_expr = lsdv_expr + ' + ' + dummy_name_mr\n",
    "#lsdv_expr = lsdv_expr + ' - ' + '1'\n",
    "print('Regression expression for OLS with dummies=' + lsdv_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.295\n",
      "Model:                            OLS   Adj. R-squared:                  0.287\n",
      "Method:                 Least Squares   F-statistic:                     37.17\n",
      "Date:                Thu, 14 Sep 2023   Prob (F-statistic):          1.89e-183\n",
      "Time:                        15:56:45   Log-Likelihood:                -8751.2\n",
      "No. Observations:                2790   AIC:                         1.757e+04\n",
      "Df Residuals:                    2758   BIC:                         1.776e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           0.1497      0.588      0.255      0.799      -1.003       1.302\n",
      "TA                  0.4516      0.219      2.060      0.040       0.022       0.882\n",
      "PA                  0.8427      0.203      4.153      0.000       0.445       1.241\n",
      "DL                  0.0501      0.040      1.241      0.215      -0.029       0.129\n",
      "Awdal              -0.4539      0.637     -0.713      0.476      -1.702       0.795\n",
      "Bakool              0.0898      0.637      0.141      0.888      -1.159       1.338\n",
      "Banadir            15.7048      0.637     24.659      0.000      14.456      16.954\n",
      "Bari                0.4005      0.638      0.628      0.530      -0.851       1.652\n",
      "Bay                 2.5406      0.637      3.985      0.000       1.291       3.791\n",
      "Galgaduud           0.4895      0.637      0.768      0.442      -0.760       1.739\n",
      "Gedo                0.4502      0.637      0.706      0.480      -0.799       1.700\n",
      "Hiraan              1.6718      0.637      2.624      0.009       0.423       2.921\n",
      "Lower_Juba          1.2552      0.637      1.970      0.049       0.006       2.505\n",
      "Lower_Shabelle      2.7146      0.637      4.262      0.000       1.466       3.964\n",
      "Middle_Juba         0.1620      0.638      0.254      0.800      -1.090       1.414\n",
      "Middle_Shabelle     0.6760      0.637      1.062      0.288      -0.572       1.924\n",
      "Mudug               0.6073      0.637      0.953      0.341      -0.642       1.857\n",
      "Nugaal              0.0458      0.637      0.072      0.943      -1.204       1.296\n",
      "Sanaag             -0.2040      0.637     -0.320      0.749      -1.454       1.046\n",
      "Sool               -0.0157      0.637     -0.025      0.980      -1.265       1.233\n",
      "Togdheer           -0.1809      0.637     -0.284      0.776      -1.429       1.068\n",
      "February           -0.0412      0.529     -0.078      0.938      -1.078       0.996\n",
      "March               0.1522      0.529      0.288      0.774      -0.885       1.190\n",
      "April               0.0612      0.531      0.115      0.908      -0.979       1.102\n",
      "May                 0.4420      0.531      0.833      0.405      -0.599       1.483\n",
      "June                0.8076      0.531      1.522      0.128      -0.233       1.848\n",
      "July                0.4297      0.530      0.810      0.418      -0.610       1.470\n",
      "August              0.3168      0.531      0.596      0.551      -0.725       1.359\n",
      "September           0.2033      0.531      0.383      0.702      -0.838       1.244\n",
      "October             0.5182      0.531      0.975      0.329      -0.523       1.560\n",
      "November           -0.0308      0.531     -0.058      0.954      -1.073       1.011\n",
      "December            0.0505      0.530      0.095      0.924      -0.989       1.090\n",
      "==============================================================================\n",
      "Omnibus:                     3157.034   Durbin-Watson:                   1.838\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           442723.863\n",
      "Skew:                           5.615   Prob(JB):                         0.00\n",
      "Kurtosis:                      63.682   Cond. No.                         73.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lsdv_model = smf.ols(formula=lsdv_expr, data=df_with_dummies)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "print(lsdv_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82327b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC = 17566.42583986604\n"
     ]
    }
   ],
   "source": [
    "#compute AIC\n",
    "print('AIC = ' + str(lsdv_model_results.aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\dist_som.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dist = 1/(dist+0.001)\n",
    "inv_dist.reset_index(inplace=True)\n",
    "inv_dist['index'] = inv_dist['index'].replace(replacement_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5037a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new=df_with_dummies.merge(inv_dist, left_on='admin1', right_on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies.drop(['index'], axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
