{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "49af736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ebf15",
   "metadata": {},
   "source": [
    "Data from POWER Data Access Viewer - NASA (1997-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "fd212166",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\POWER_Regional_monthly_1997_2020.nc\"\n",
    "da2 = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\POWER_Regional_monthly_1997_2020_south.nc\"\n",
    "\n",
    "file_paths_list =[da1,da2]\n",
    "monthly_forecast=xr.Dataset()\n",
    "\n",
    "for file in file_paths_list:\n",
    "        monthly_forecast = xr.merge([monthly_forecast,xr.open_mfdataset(file)], compat='no_conflicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "35124662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'T2M_MAX':'tmx' in monthly_forecast\n",
    "monthly_forecast = monthly_forecast.rename({'T2M_MAX':'tmx','PRECTOTCORR':'pre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "48b87061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the extra month\n",
    "monthly_forecast = monthly_forecast.sel(time=~((monthly_forecast.time.astype(str).str[4:6] == '13') ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53f58",
   "metadata": {},
   "source": [
    "Data on conflict events from ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "45e1de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\ACLED_1997-01-01-2023-07-18_Somalia.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "#remove events types of strategic developments\n",
    "df = df[df['event_type'] != 'Strategic developments']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f32fa7",
   "metadata": {},
   "source": [
    "Shapefile with administrative boundaries of Somalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "140d777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\Datasets\\som_adm_ocha_itos_20230308_shp\\som_admbnda_adm1_ocha_20230308.shp\"\n",
    "states_gdf = gpd.read_file(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a83aa8",
   "metadata": {},
   "source": [
    "Limit the lat-lon and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "e4ad81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aoi(shp, world=True):\n",
    "    lon_lat = {}\n",
    "    # Get lat min, max\n",
    "    aoi_lat = [float(shp.total_bounds[1]), float(shp.total_bounds[3])]\n",
    "    aoi_lon = [float(shp.total_bounds[0]), float(shp.total_bounds[2])]\n",
    "\n",
    "    lon_lat[\"lon\"] = aoi_lon\n",
    "    lon_lat[\"lat\"] = aoi_lat\n",
    "    return lon_lat\n",
    "\n",
    "bounds = get_aoi(states_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "e765a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1980-01-01'\n",
    "end_date = '2020-12-31'\n",
    "\n",
    "region = monthly_forecast[[\"pre\",'tmx']].sel(\n",
    "    time=slice(start_date, end_date),\n",
    "    lon=slice(bounds[\"lon\"][0], bounds[\"lon\"][1]),\n",
    "    lat=slice(bounds[\"lat\"][0], bounds[\"lat\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "1382c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mask = regionmask.mask_3D_geopandas(states_gdf,\n",
    "                                         monthly_forecast.lon,\n",
    "                                         monthly_forecast.lat)\n",
    "\n",
    "temp_pre = region.where(region_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "ac72c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre['time']=temp_pre['time'].astype(str)\n",
    "temp_pre = temp_pre.groupby(\"time\").mean([\"lat\", \"lon\"]).to_dataframe().reset_index()\n",
    "temp_pre['time'] = temp_pre['time'].str[:4] + '-' + temp_pre['time'].str[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "74921595",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {0  :  'Awdal',\n",
    "1    :         'Bakool',\n",
    "2      :       'Banadir',\n",
    "3      :         'Bari',\n",
    "4       :         'Bay',\n",
    "5        :  'Galgaduud',\n",
    "6          :      'Gedo',\n",
    "7          :   'Hiraan',\n",
    "8   :       'Lower_Juba',\n",
    "9   :   'Lower_Shabelle',\n",
    "10  :      'Middle_Juba',\n",
    "11   : 'Middle_Shabelle',\n",
    "12    :          'Mudug',\n",
    "13    :        'Nugaal',\n",
    "14      :       'Sanaag',\n",
    "15       :        'Sool',\n",
    "16        :   'Togdheer',\n",
    "17   : 'Woqooyi_Galbeed'}\n",
    "\n",
    "temp_pre['admin1'] = temp_pre['region'].replace(replacement_dict)\n",
    "df['admin1'] = df['admin1'].str.replace(' ', '_')\n",
    "temp_pre.drop('region', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "647d91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify event_date column to datetime\n",
    "\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df = df.set_index('event_date') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "f50e3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = df.groupby([pd.Grouper(freq='M'),\"admin1\"]).count()\n",
    "conflict.reset_index(level=[0, 1], inplace=True)\n",
    "conflict = conflict[['event_date','admin1','year']].rename(columns={'year': 'conflicts','event_date': 'time'})\n",
    "\n",
    "# Aggregate the datetime objects by month\n",
    "conf = conflict.groupby([pd.Grouper(key='time', freq='M'),'admin1'])['conflicts'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "ee086f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame with all dates and districts and fill missing values with 0\n",
    "\n",
    "dates = conf.index.get_level_values('time').unique()\n",
    "districts = conf.index.get_level_values('admin1').unique()\n",
    "all_combinations = pd.MultiIndex.from_product([dates, districts], names=['time', 'admin1'])\n",
    "\n",
    "conflicts = conf.reindex(all_combinations, fill_value=0).reset_index()    \n",
    "conflicts = conflicts.sort_values(by=['time', 'admin1'], ascending=[True, True])\n",
    "conflicts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "f8b312de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Banadir region with tmx and pre as mean of the neighbouring regions\n",
    "\n",
    "district1 = 'Lower_Shabelle'  \n",
    "district2 = 'Middle_Shabelle'  \n",
    "\n",
    "# Calculate the mean tmx and pre for the neighboring districts\n",
    "mean_t = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['tmx'].mean()\n",
    "mean_p = temp_pre[(temp_pre['admin1']==district1) | (temp_pre['admin1']==district2)].groupby('time')['pre'].mean()\n",
    "\n",
    "new_data = pd.DataFrame({ 'admin1': 'Banadir', 'tmx': mean_t, 'pre': mean_p}).reset_index()\n",
    "\n",
    "# Append the new DataFrame to the original DataFrame\n",
    "df3 = pd.concat([temp_pre, new_data])\n",
    "temp_pre = df3.sort_values(by=['time', 'admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "7dbb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre['month'] = temp_pre['time'].str[5:7]\n",
    "conflicts['time'] = conflicts['time'].dt.strftime('%Y-%m').values\n",
    "temp_pre = temp_pre[['time','admin1','tmx','pre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "e4a05554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into regions\n",
    "\n",
    "reg=[]\n",
    "for admin in temp_pre['admin1'].unique():\n",
    "    a = temp_pre[temp_pre['admin1']==admin].reset_index(drop=True)\n",
    "    reg.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "80cdd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TA (temperature anomaly), PA (precipitation anomaly) and DL (drought lenght) for each region\n",
    "\n",
    "avg_t = avg_p = std_t = std_p = np.zeros(18)\n",
    "\n",
    "for i in range(18):\n",
    "\n",
    "    reg[i]['year'] , reg[i]['month'] = reg[i]['time'].str[:4] , reg[i]['time'].str[5:7]\n",
    "\n",
    "    # TA\n",
    "    mean_temp_i , std_temp_i  = reg[i].groupby('month')['tmx'].mean() , reg[i].groupby('month')['tmx'].std()\n",
    "    reg[i]['avg_temp'] , reg[i]['std_temp']  = reg[i]['month'].map(mean_temp_i) , reg[i]['month'].map(std_temp_i)\n",
    "    reg[i]['diff_t']= (reg[i]['tmx']-reg[i]['avg_temp'])/reg[i]['std_temp']\n",
    "    reg[i]['TA'] = (reg[i]['diff_t'].shift(2) + reg[i]['diff_t'].shift(1) + reg[i]['diff_t'])/3\n",
    "\n",
    "    # PA\n",
    "    mean_pre_i , std_pre_i  = reg[i].groupby('month')['pre'].mean() , reg[i].groupby('month')['pre'].std()\n",
    "    reg[i]['avg_pre'] , reg[i]['std_pre']= reg[i]['month'].map(mean_pre_i) , reg[i]['month'].map(std_pre_i)\n",
    "    reg[i]['diff_p']= (reg[i]['pre']-reg[i]['avg_pre'])/reg[i]['std_pre']\n",
    "    reg[i]['PA'] = (reg[i]['diff_p'].shift(2) + reg[i]['diff_p'].shift(1) + reg[i]['diff_p'])/3\n",
    "    \n",
    "    # DL \n",
    "    reg[i]['DL'] = 0\n",
    "    mask = reg[i]['TA'] > 0\n",
    "    group_id = (mask != mask.shift()).cumsum()             # Create a group identifier for each consecutive group\n",
    "    count = reg[i].groupby(group_id).cumcount() + 1        # Calculate the count within each group\n",
    "    reg[i]['DL'] = np.where(mask, count, 0)                # Assign the count values to the 'DL' column\n",
    "\n",
    "    # add columns TA_lag1, TA_lag2, TA_lag3, TA_lag4, PA_lag1, PA_lag2, DL_lag1, DL_lag2, DL_lag3, DL_lag4, DL_lag5\n",
    "    # reg[i]['TA_lag1'] = reg[i]['TA'].shift(1)\n",
    "    # reg[i]['TA_lag2'] = reg[i]['TA'].shift(2)\n",
    "    # reg[i]['TA_lag3'] = reg[i]['TA'].shift(3)\n",
    "    # reg[i]['TA_lag4'] = reg[i]['TA'].shift(4)\n",
    "    # reg[i]['TA_lag5'] = reg[i]['TA'].shift(5)\n",
    "\n",
    "    # reg[i]['PA_lag1'] = reg[i]['PA'].shift(1)\n",
    "    # reg[i]['PA_lag2'] = reg[i]['PA'].shift(2)\n",
    "    # reg[i]['PA_lag3'] = reg[i]['PA'].shift(3)\n",
    "    # reg[i]['PA_lag4'] = reg[i]['PA'].shift(4)\n",
    "    # reg[i]['PA_lag5'] = reg[i]['PA'].shift(5)\n",
    "\n",
    "    # reg[i]['DL_lag1'] = reg[i]['DL'].shift(1)\n",
    "    # reg[i]['DL_lag2'] = reg[i]['DL'].shift(2)\n",
    "    # reg[i]['DL_lag3'] = reg[i]['DL'].shift(3)\n",
    "    # reg[i]['DL_lag4'] = reg[i]['DL'].shift(4)\n",
    "    # reg[i]['DL_lag5'] = reg[i]['DL'].shift(5)\n",
    "\n",
    "    reg[i] = reg[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "3dd81ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pre_c = pd.concat([reg[i] for i in range(18)], axis=0)\n",
    "temp_pre_c = temp_pre_c.dropna()\n",
    "# Select a subset of the dataframes from 1997-01 to 2009-12\n",
    "\n",
    "start='1997-01'\n",
    "end='2009-12'\n",
    "temp_pre_97_09 = temp_pre_c[(temp_pre_c['time'] >= start) & (temp_pre_c['time'] <= end)]\n",
    "conflicts_97_09 = conflicts[(conflicts['time'] >= start) & (conflicts['time'] <= end)]\n",
    "\n",
    "df_c_97_09 = pd.merge(temp_pre_97_09, conflicts_97_09, on=['time','admin1'], how='outer')\n",
    "df_c_97_09 = df_c_97_09.fillna(0)\n",
    "df_c_97_09 = df_c_97_09.drop(['avg_temp', 'avg_pre', 'std_temp', 'std_pre', 'diff_t', 'diff_p', 'tmx', 'pre'], axis=1)\n",
    "df_c_97_09 = df_c_97_09.sort_values(by=['time','admin1'], ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "a1d7743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummy variables\n",
    "\n",
    "#one for each country\n",
    "df_dummies = pd.get_dummies(df_c_97_09['admin1'])\n",
    "df_with_dummies = df_c_97_09.join(df_dummies)\n",
    "\n",
    "#one for each month\n",
    "df_c_97_09['month'] = pd.DatetimeIndex(df_c_97_09['time']).month_name()\n",
    "df_dummies_m = pd.get_dummies(df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_m)\n",
    "df_with_dummies['month'] = pd.DatetimeIndex(df_c_97_09['time']).month\n",
    "\n",
    "#one for each for each country-month pair\n",
    "df_dummies_mr = pd.get_dummies(df_c_97_09['admin1'] + df_c_97_09['month'])\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_mr)\n",
    "df_with_dummies = df_with_dummies.replace({True: 1, False: 0})\n",
    "\n",
    "#create a dictionary where the keys are increasing integers and the values are the values of the time column\n",
    "time_dict = dict(enumerate(df_c_97_09['time'].unique(), 25))\n",
    "inv_time_dict = {v: k for k, v in time_dict.items()}\n",
    "\n",
    "#create a new variable for the month_year column\n",
    "df_c_97_09['time'].replace(inv_time_dict, inplace=True)\n",
    "\n",
    "df_dummies_new = pd.get_dummies(df_c_97_09['time'].astype(str), drop_first=True)\n",
    "df_dummies_new = df_dummies_new.replace({True: 1, False: 0})\n",
    "df_with_dummies = df_with_dummies.join(df_dummies_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "d0888b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_name = 'conflicts'\n",
    "X_var_names = ['TA','PA','DL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "a893f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression expression for OLS with dummies=conflicts ~ TA + PA + DL + AwdalJanuary + BakoolJanuary + BanadirJanuary + BariJanuary + BayJanuary + GalgaduudJanuary + GedoJanuary + HiraanJanuary + Lower_JubaJanuary + Lower_ShabelleJanuary + Middle_JubaJanuary + Middle_ShabelleJanuary + MudugJanuary + NugaalJanuary + SanaagJanuary + SoolJanuary + TogdheerJanuary\n"
     ]
    }
   ],
   "source": [
    "# Regression expression for OLS with dummies\n",
    "\n",
    "unit_names = df_c_97_09['admin1'].unique().tolist()\n",
    "unit_names.sort()\n",
    "unit_names_t = df_c_97_09['month'].unique().tolist()\n",
    "unit_names_my = df_c_97_09['time'].astype(str).unique().tolist()\n",
    "unit_names_mr = (df_c_97_09['admin1'] + df_c_97_09['month']).unique().tolist()\n",
    "unit_names_myr = (df_c_97_09['admin1'] + df_c_97_09['time'].astype(str)).unique().tolist()\n",
    "\n",
    "lsdv_expr = y_var_name + ' ~ '\n",
    "i = 0\n",
    "for X_var_name in X_var_names:\n",
    "    if i > 0:\n",
    "        lsdv_expr = lsdv_expr + ' + ' + X_var_name\n",
    "    else:\n",
    "        lsdv_expr = lsdv_expr + X_var_name\n",
    "    i = i + 1\n",
    "#for dummy_name in unit_names[:-1]:\n",
    "  # lsdv_expr = lsdv_expr + ' + ' + dummy_name\n",
    "#or dummy_name_t in unit_names_t[:-1]:\n",
    "   #lsdv_expr = lsdv_expr + ' + ' + dummy_name_t\n",
    "for dummy_name_mr in unit_names_mr[:-1]:\n",
    "    lsdv_expr = lsdv_expr + ' + ' + dummy_name_mr\n",
    "#lsdv_expr = lsdv_expr + ' - ' + '1'\n",
    "print('Regression expression for OLS with dummies=' + lsdv_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "9af6641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              conflicts   R-squared:                       0.295\n",
      "Model:                            OLS   Adj. R-squared:                  0.287\n",
      "Method:                 Least Squares   F-statistic:                     37.17\n",
      "Date:                Thu, 14 Sep 2023   Prob (F-statistic):          1.89e-183\n",
      "Time:                        15:56:45   Log-Likelihood:                -8751.2\n",
      "No. Observations:                2790   AIC:                         1.757e+04\n",
      "Df Residuals:                    2758   BIC:                         1.776e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           0.1497      0.588      0.255      0.799      -1.003       1.302\n",
      "TA                  0.4516      0.219      2.060      0.040       0.022       0.882\n",
      "PA                  0.8427      0.203      4.153      0.000       0.445       1.241\n",
      "DL                  0.0501      0.040      1.241      0.215      -0.029       0.129\n",
      "Awdal              -0.4539      0.637     -0.713      0.476      -1.702       0.795\n",
      "Bakool              0.0898      0.637      0.141      0.888      -1.159       1.338\n",
      "Banadir            15.7048      0.637     24.659      0.000      14.456      16.954\n",
      "Bari                0.4005      0.638      0.628      0.530      -0.851       1.652\n",
      "Bay                 2.5406      0.637      3.985      0.000       1.291       3.791\n",
      "Galgaduud           0.4895      0.637      0.768      0.442      -0.760       1.739\n",
      "Gedo                0.4502      0.637      0.706      0.480      -0.799       1.700\n",
      "Hiraan              1.6718      0.637      2.624      0.009       0.423       2.921\n",
      "Lower_Juba          1.2552      0.637      1.970      0.049       0.006       2.505\n",
      "Lower_Shabelle      2.7146      0.637      4.262      0.000       1.466       3.964\n",
      "Middle_Juba         0.1620      0.638      0.254      0.800      -1.090       1.414\n",
      "Middle_Shabelle     0.6760      0.637      1.062      0.288      -0.572       1.924\n",
      "Mudug               0.6073      0.637      0.953      0.341      -0.642       1.857\n",
      "Nugaal              0.0458      0.637      0.072      0.943      -1.204       1.296\n",
      "Sanaag             -0.2040      0.637     -0.320      0.749      -1.454       1.046\n",
      "Sool               -0.0157      0.637     -0.025      0.980      -1.265       1.233\n",
      "Togdheer           -0.1809      0.637     -0.284      0.776      -1.429       1.068\n",
      "February           -0.0412      0.529     -0.078      0.938      -1.078       0.996\n",
      "March               0.1522      0.529      0.288      0.774      -0.885       1.190\n",
      "April               0.0612      0.531      0.115      0.908      -0.979       1.102\n",
      "May                 0.4420      0.531      0.833      0.405      -0.599       1.483\n",
      "June                0.8076      0.531      1.522      0.128      -0.233       1.848\n",
      "July                0.4297      0.530      0.810      0.418      -0.610       1.470\n",
      "August              0.3168      0.531      0.596      0.551      -0.725       1.359\n",
      "September           0.2033      0.531      0.383      0.702      -0.838       1.244\n",
      "October             0.5182      0.531      0.975      0.329      -0.523       1.560\n",
      "November           -0.0308      0.531     -0.058      0.954      -1.073       1.011\n",
      "December            0.0505      0.530      0.095      0.924      -0.989       1.090\n",
      "==============================================================================\n",
      "Omnibus:                     3157.034   Durbin-Watson:                   1.838\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           442723.863\n",
      "Skew:                           5.615   Prob(JB):                         0.00\n",
      "Kurtosis:                      63.682   Cond. No.                         73.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lsdv_model = smf.ols(formula=lsdv_expr, data=df_with_dummies)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "print(lsdv_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "c82327b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC = 17566.42583986604\n"
     ]
    }
   ],
   "source": [
    "#compute AIC\n",
    "print('AIC = ' + str(lsdv_model_results.aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "a994ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.read_csv(r\"C:\\Users\\PcLaptop\\Documents\\GitHub\\Climate-and-conflict\\dist_som.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "78de8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dist = 1/(dist+0.001)\n",
    "inv_dist.reset_index(inplace=True)\n",
    "inv_dist['index'] = inv_dist['index'].replace(replacement_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "a5037a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new=df_with_dummies.merge(inv_dist, left_on='admin1', right_on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "fd88af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies.drop(['index'], axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
